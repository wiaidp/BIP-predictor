% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass[a4paper]{article}

\title{BIP-Predictor}
\author{Marc Wildi\\
Zurich University of Applied Sciences (ZHAW)\\
8000 Zurich, Switzerland\\
marc.wildi@zhaw.ch}


\SweaveOpts{echo=FALSE}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{amsfonts} 
\usepackage{amsthm}
\usepackage{ amssymb }
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{float}
\newtheorem{Proposition}{Proposition}
\newtheorem{Corollary}{Corollary}
\newtheorem{Theorem}{Theorem}
\DeclareMathOperator{\sign}{sign}
%- Makes the section title start with Appendix in the appendix environment
\newcommand{\Appendix}
{%\appendix
\def\thesection{Appendix~\Alph{section}}
%\def\thesubsection{\Alph{section}.\arabic{subsection}}
\def\thesubsection{A.\arabic{subsection}}
}

\begin{document}

\maketitle

\begin{abstract}
\noindent 

\end{abstract}

~\\
~\\




%\tableofcontents

\section{Introduction}



\section{Data and Dependence}

<<label=init,results=hide>>=

rm(list=ls())

inst_pack<-rownames(installed.packages())
if (!"mFilter"%in%inst_pack)
  install.packages("mFilter")
if (!"xts"%in%inst_pack)
  install.packages("xts")
if (!"MTS"%in%inst_pack)
  install.packages("MTS")
if (!"sandwich"%in%inst_pack)
  install.packages("sandwich")
if (!"multDM"%in%inst_pack)
  install.packages("multDM")
if (!"fGarch"%in%inst_pack)
  install.packages("fGarch")
if (!"xtable"%in%inst_pack)
  install.packages("xtable")
if (!"MASS"%in%inst_pack)
  install.packages("MASS")
if (!"glmnet"%in%inst_pack)
  install.packages("glmnet")
if (!"pROC"%in%inst_pack)
  install.packages("pROC")





# Load the required R-libraries
# Standard filter package
library(mFilter)
# Multivariate time series: VARMA model for macro indicators: used here for simulation purposes only
library(MTS)
# HAC estimate of standard deviations in the presence of autocorrelation and heteroscedasticity
library(sandwich)
# Library for Diebold-Mariano test of equal forecast performance
library(multDM)
# GARCH model: for improving regression estimates
library(fGarch)
# Library for tables
library(xtable)
# Packages for Ridge and LASSO
library(MASS)
library(glmnet) 
# Extended time series
library(xts)
# Extended time series
library(pROC)




# Load the relevant M-SSA functionalities
# M-SSA functions
source(paste(getwd(),"/R/functions_MSSA.r",sep=""))
# Load signal extraction functions used for JBCY paper (relies on mFilter)
source(paste(getwd(),"/R/HP_JBCY_functions.r",sep=""))
# Utility functions for M-SSA, see tutorial 
source(paste(getwd(),"/R/M_SSA_utility_functions.r",sep=""))
source(paste(getwd(),"/R/M_SSA_paper_functions.r",sep=""))
# ROC curve: plots, AUC
source(paste(getwd(),"/R/ROCplots.r",sep=""))





 
path.main<-getwd()

path.pgm<-paste(path.main,"/R/",sep="")
path.out<-paste(path.main,"/Latex/",sep="")
path.sweave<-paste(path.main,"/Sweave/",sep="")
path.data<-paste(path.main,"/Data/",sep="")
# Savd results from an empirical analysis of S&P500
path.result<-paste(path.main,"/Results/",sep="")
fig_size<-4

#------------------------------
# Section 2.1: data
recompute_results<-F





# Load data
data_file_name<-c("Data_HWI_2025_02.csv","gdp_2025_02.csv")
# Original (un-transformed) indicators
data_quarterly<-read.csv(paste(getwd(),"/Data/",data_file_name[2],sep=""))
BIP_original<-data_quarterly[,"BIP"]
# Transformed indicators: differences, trimmed, standardized
load(file=paste(getwd(),"\\Data\\macro",sep=""))

select_vec_multi<-c("BIP","ip","ifo_c","ESI","spr_10y_3m")
x_mat<-data[,select_vec_multi] 
rownames(x_mat)<-rownames(data)
n<-dim(x_mat)[2]
# Number of observations
len<-dim(x_mat)[1]

# Read original data 
h0<-0
trim_threshold<-3
na_rw_lin<-T
data_file_name<-c("Data_HWI_2025_02.csv","gdp_2025_02.csv")
select_vec<-select_vec_multi
diff_lag<-3


read_obj<-read_data_func_monthly(path.data,select_vec,h0,trim_threshold,na_rw_lin,data_file_name,diff_lag)
data_table<-read_obj$data_select_unshifted_xts
colnames(data_table)[1]<-"GDP"

tail(data_table)


# Settings for M-SSA
ht_mssa_vec<-c(6.380160,  6.738270,   7.232453,   7.225927,   7.033768)
f_excess<-c(5,rep(4,length(select_vec_multi)-1))
# In-smaple span for VAR
date_to_fit<-"2008"
# Model orders
p<-1
q<-0
# Filter length
L<-31
# Publication lag: one quarter for BIP
lag_vec<-c(1,rep(0,ncol(x_mat)-1))

# Use OLS or WLS in regression of shifted BIP on M-SSA component predictor 
use_garch<-F

#------------------------------------------------------
# Section 1: data
# Plots section data

# Plot BIP and diff-log BIP
file = "./Figures/data.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)
par(mfrow=c(1,1))
colo<-c("black", "red", "green", "blue", "orange", "dimgray")
mplot<-x_mat
colnames(mplot)[1]<-"GDP"
main_title<-"Data: standardized diff-log, Pandemic outliers trimmed"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
box()
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")


dev.off()









# Plot BIP and diff-log BIP
file = "./Figures/data_lags.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)

par(mfrow=c(1,2))
# Plot the data
# The real-time BIP (red) is lagging the target (black) by lag_vec[1] quarters (publication lag)
mplot<-x_mat[which(rownames(x_mat)>=2007&rownames(x_mat)<=2011),]
colnames(mplot)[1]<-"GDP"
plot(mplot[,1],main="Financial crisis",axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
box()
#legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
mplot<-x_mat[which(rownames(x_mat)>=2019&rownames(x_mat)<=2022),]
colnames(mplot)[1]<-"GDP"
plot(mplot[,1],main="Pandemic",axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
box()
#legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

dev.off()




#--------------------------------------------------------
# Section 2.2: dependence



acf_mat<-x_mat

# Plot Cross correlation: with Pandemic
file = "./Figures/CCF.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)
#acf(x_mat)
acf_result <- acf(x_mat, plot = FALSE)

# Extract the ACF values and lags
acf_values <- acf_result$acf
lags <- acf_result$lag

par(mfrow=c(1,2))
k<-3
plot(lags[,1,length(select_vec_multi)],acf_values[,1,k], type = "h", main = paste("GDP vs. ",select_vec_multi[k],sep=""), xlab = "Lag", ylab = "CCF")
abline(h = 0, col = "red")
k<-4
plot(lags[,1,length(select_vec_multi)],acf_values[,1,k], type = "h", main = paste("GDP vs. ",select_vec_multi[k],sep=""), xlab = "Lag", ylab = "")
abline(h = 0, col = "red")

dev.off()



# Data without pandemic
x_mat_wc<-x_mat[which(rownames(x_mat)<2020|rownames(x_mat)>2021),]


# CCF without Pandemic
file = "./Figures/CCF_wc.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)
#acf(x_mat[which(rownames(acf_mat)<2020),])
acf_result <- acf(x_mat_wc, plot = FALSE)

# Extract the ACF values and lags
acf_values <- acf_result$acf
lags <- acf_result$lag

par(mfrow=c(1,2))
k<-3
plot(lags[,1,length(select_vec_multi)],acf_values[,1,k], type = "h", main = paste("GDP vs. ",select_vec_multi[k],sep=""), xlab = "Lag", ylab = "CCF")
abline(h = 0, col = "red")
k<-4
plot(lags[,1,length(select_vec_multi)],acf_values[,1,k], type = "h", main = paste("GDP vs. ",select_vec_multi[k],sep=""), xlab = "Lag", ylab = "")
abline(h = 0, col = "red")

dev.off()




# Without Covid
# Full sample

if (recompute_results)
{
  data_fit<-x_mat

  set.seed(12)
  V_obj<-VARMA(data_fit,p=p,q=q)
  threshold<-1.5
  V_obj<-refVARMA(V_obj, thres = threshold)
  save(V_obj,file=paste(path.result,"/VAR",sep=""))
# Without Pandemic  
  data_fit<-x_mat_wc
  set.seed(12)
  V_obj_wc<-VARMA(data_fit,p=p,q=q)
  threshold<-1.5
  V_obj_wc<-refVARMA(V_obj_wc, thres = threshold)
  save(V_obj_wc,file=paste(path.result,"/VAR_wc",sep=""))

} else
{
    load(file=paste(path.result,"/VAR",sep=""))
    load(file=paste(path.result,"/VAR_wc",sep=""))

}

# Diagnostics are OK
if (F)
  MTSdiag(V_obj)


# MA inversion
# Full data-set
data_fit<-x_mat
# Sigma
Sigma<-V_obj$Sigma
V_obj$Phi
V_obj$Theta
n<-dim(Sigma)[1]
# MA inversion
xi_psi<-PSIwgt(Phi = V_obj$Phi, Theta = V_obj$Theta, lag = L, plot = F, output = F)
xi_p<-xi_psi$psi.weight
# Transform Xi_p into Xi: first L entries, from left to right, are weights of first WN, next L entries are weights of second WN 
xi<-matrix(nrow=n,ncol=n*L)
for (i in 1:n)
{
  for (j in 1:L)
    xi[,(i-1)*L+j]<-xi_p[,i+(j-1)*n]
}

# Plot MA inversions

file = "./Figures/ma_inv_multi_ip.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)
colo<-rainbow(ncol(x_mat))
k<-1
par(mfrow=c(1,k))
for (i in 1:k)#i<-1
{
  select_vec_i<-select_vec_multi
  colo_i<-colo
  mplot<-xi[i,1:min(10,L)]
    
  for (j in 2:n)
  {
    mplot<-cbind(mplot,xi[i,(j-1)*L+1:min(10,L)])
      
  }
  mplot_with_pandemic<-mplot
  colnames(mplot_with_pandemic)<-c("GDP",select_vec_i[2:length(select_vec_i)])
  ts.plot(mplot,col=colo_i,main=paste("MA inversion ",colnames(data_fit)[i],sep=""),xlab="lag")
  for (k in 1:length(select_vec_i))
  { 
    if (k==1)
    {
      mtext("GDP",line=-k,col=colo_i[k])
    } else
    {
      mtext(select_vec_i[k],line=-k,col=colo_i[k])
    }
  }
}

dev.off()

# Without Pandemic
# Sigma
Sigma<-V_obj_wc$Sigma
# MA inversion
xi_psi<-PSIwgt(Phi = V_obj_wc$Phi, Theta = V_obj_wc$Theta, lag = L, plot = F, output = F)
xi_p<-xi_psi$psi.weight
# Transform Xi_p into Xi: first L entries, from left to right, are weights of first WN, next L entries are weights of second WN 
xi<-matrix(nrow=n,ncol=n*L)
for (i in 1:n)
{
  for (j in 1:L)
    xi[,(i-1)*L+j]<-xi_p[,i+(j-1)*n]
}

# Plot MA inversions  
file = "./Figures/ma_inv_multi_ip_wc.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)
colo<-rainbow(ncol(x_mat))
k<-1
par(mfrow=c(1,k))
for (i in 1:k)#i<-1
{
  select_vec_i<-select_vec_multi
  colo_i<-colo
  mplot<-xi[i,1:min(10,L)]
    
  for (j in 2:n)
  {
    mplot<-cbind(mplot,xi[i,(j-1)*L+1:min(10,L)])
      
  }
    mplot_without_pandemic<-mplot
  colnames(mplot_without_pandemic)<-c("GDP",select_vec_i[2:length(select_vec_i)])

  ts.plot(mplot,col=colo_i,main=paste("MA inversion ",colnames(data_fit)[i],sep=""),xlab="lag")
  for (k in 1:length(select_vec_i))
  { 
    if (k==1)
    {
      mtext("GDP",line=-k,col=colo_i[k])
    } else
    {
      mtext(select_vec_i[k],line=-k,col=colo_i[k])
    }
  }
}

dev.off()




file = "./Figures/ma_inv_BIP.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 9, height = 6)
colo<-c("black", "red", "green", "blue", "orange", "dimgray")
par(mfrow=c(1,2))
plot(mplot_with_pandemic[,1],main=paste("MA inversion GDP: with pandemic",sep=""),axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot_with_pandemic)),max(na.exclude(mplot_with_pandemic))))

for (i in 1:ncol(mplot_with_pandemic))
{
  lines(mplot_with_pandemic[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=1:nrow(mplot)-1)
axis(2)
legend("topright", legend = colnames(mplot_with_pandemic), col = colo, lty = 1, lwd = 1, bty = "n")
box()

plot(mplot_without_pandemic[,1],main=paste("Without pandemic",sep=""),axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot_without_pandemic)),max(na.exclude(mplot_without_pandemic))))

for (i in 1:ncol(mplot_without_pandemic))
{
  lines(mplot_without_pandemic[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=1:nrow(mplot)-1)
axis(2)
box()


dev.off()







@



\subsection{Data}

\begin{itemize}
\item Choice of indicators: BIP, ip, ESI, ifo, spread
\item Quarterly frequency (emphasize $h\geq 2$)
\item Data transformations: Diff-log, standardization (merely for ease of visual inspection), trim Covid ourliers
\item Revisions and publication lags:  BIP lagged by quarter and ip lagged by two months in Jan-2025 data set
\item Real-time data: all series are artificially aligned at end point. BIP and ip are advanced by their lags.
\end{itemize}

<<label=ats_mba_2,echo=FALSE,results=tex>>=

mat1<-as.matrix(tail(data_table,7))
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("Ragged end.  "),
label=paste("f_stat",sep=""),
center = "centering", file = "", floating = FALSE)

math<-as.matrix(tail(data_table,10))
mat2<-cbind(math[2:7,1],math[3:8,2],math[5:10,3:5])
colnames(mat2)<-colnames(mat1)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat2, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("Data aligned at sample end."),
label=paste("f_stat",sep=""),
center = "centering", file = "", floating = FALSE)


@


The transformed quarterly series are displayed in Fig. \ref{data}, while Fig. \ref{data_lags} offers a close-up view of the financial crisis and the pandemic. The latter figure illustrates that the real-time GDP and industrial production series are synchronized at dips and peaks (coincident), whereas the other indicators tend to lead in relative terms. This characteristic of the additional explanatory variables can be leveraged in a multivariate approach to enhance forecasting performance compared to univariate benchmarks. 


<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/Data.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Data: standardized log-differences. Data trimmed to $\\pm 3$ for ease of visual inspection.", sep = "")
cat("\\label{data}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@

<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/data_lags.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Data: leads and lags during financial crisis (left) and Pandemic (right). Data trimmed to $\\pm 3$ for ease of visual inspection.", sep = "")
cat("\\label{data_lags}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@





\subsection{Dependence}

We analyze the dependence structure of the data and derive a simple VAR model to establish the multivariate filter. The sample cross-correlation function (CCF) is shown in Figs. \ref{CCF} (entire dataset) and \ref{CCF_wc} (data prior to the pandemic).  
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/CCF.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Sample cross-correlation function: GDP and ifo (left), GDP and ESI (right): full data set, including the pandemic. Correlations at positive lags signify that (real-time) GDP is lagging when referenced against the two (real-time) indicators.", sep = "")
cat("\\label{CCF}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/CCF_wc.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Sample cross-correlation function: GDP and ifo (left), GDP and ESI (right): without pandemic. Correlations at positive lags signify that (real-time) GDP is lagging when referenced against the two (real-time) indicators.", sep = "")
cat("\\label{CCF_wc}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
The CCF confirms the leads and lags illustrated in Fig. \ref{data_lags}, although the strength of the dependence is influenced by the singular readings during the pandemic\footnote{We discard the corresponding data when finalizing the predictor.}. We can now fit a VARMA model, and according to standard diagnostic tests (not shown here), a simple VAR(1) specification aligns with the data. The resulting impulse responses of the model are presented in Figs. \ref{impulse} (full data set) and \eqref{impulse_wc} (prior the pandemic).
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/ma_inv_multi_ip.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{MA inversion of VAR(1): full data set.", sep = "")
cat("\\label{impulse}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/ma_inv_multi_ip_wc.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{MA inversion of VAR(1): without Pandemic.", sep = "")
cat("\\label{impulse_wc}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/ma_inv_BIP.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{MA inversion of VAR(1) for GDP: with pandemic (left) and without pandemic (right).", sep = "")
cat("\\label{ma_inv_BIP}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@



The model summarizes key features of the data, where lagging series (GDP and industrial production, when accounting for publication lags) depend on  indicators leading in relative terms. In particular, the impulse response of the spread (rightmost panel in the figure) suggests the relevance of a univariate model for this specific leading indicator.


\section{Direct Forecasts}\label{direct_forecast}

\subsection{`Classic' Direct Forecast}\label{cdf}

So-called direct forecasts are obtained by regressing the relevant indicators on forward-shifted BIP, accounting for the additional publication lag. For illustration of the concept, we here rely on all indicators and full sample information, excluding the pandemic. In-sample forecasts and the shifted BIP, which serves as the target, are presented in Figs. \ref{direct_wc} (full dataset without the pandemic) and \ref{direct_wc_financial_crisis} (financial crisis) for horizons up to three quarters ahead. 
<<label=init,results=hide>>=
# Section 3.1: classic direct forecasts

# Select indicators: we select all indicators and regression is entirely in-sample
#   -Ideal case: performances too good (overfitting)
#   -in applications the regression is out-of-sample (ifo and ESI work best out-of-sample) 

# Plot of direct forecasts without Pandemic
file = "./Figures/direct_wc_all.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7.5, height = 6)

par(mfrow=c(2,2))
select_direct_indicator<-select_vec_multi

# Note: too complex designs (too many indicators) lead to overfitting and thus worse out-of-sample performances
# To illustrate the direct predictor consider the following example of a h-step ahead direct forecast:
f_vec_unfiltered<-p_val_unfiltered<-MSE_unfiltered_vec<-NULL
for (h in 0:3)
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected indicators on forward-shifted BIP: start at t=L (same sample as HP-C)
  lm_obj<-lm(forward_shifted_BIP[L:length(forward_shifted_BIP)]~x_mat_wc[L:nrow(x_mat_wc),select_direct_indicator])
  # You will probably not find statistically significant regressors for h>2: BIP is a noisy series
  summary(lm_obj)
  sum_obj<-sum_obj_unfiltered<-summary(lm_obj)
  MSE_unfiltered_vec<-c(MSE_unfiltered_vec,sum_obj$sigma^2)

  f_vec_unfiltered<-c(f_vec_unfiltered,sum_obj$fstatistic["value"])  
  p_val_unfiltered<-c(p_val_unfiltered,pf(sum_obj$fstatistic["value"], sum_obj$df[1],sum_obj$df[2], lower.tail = FALSE))

  # Technical note: 
  # -Residuals are subject to heteroscedasticity (crises) and autocorrelation
  # -Therefore classic OLS tests for statistical significance are biased
  # -We shall rely on HAC-adjusted p-values further down (R-package sandwich)
  
  # Compute the predictor: one can rely on the generic R-function predict or compute the predictor manually
  direct_forecast<-lm_obj$coef[1]+x_mat_wc[,select_direct_indicator]%*%lm_obj$coef[2:(length(select_direct_indicator)+1)]
  # Note that this is a full-sample predictor (no out-of-sample span)
  
  # We can now plot target and direct forecast: for h>2 the predictor comes close to a flat line centered at zero
  mplot<-cbind(forward_shifted_BIP,direct_forecast)
  rownames(mplot)<-rownames(x_mat_wc)
  colnames(mplot)<-c("GDP","Direct forecast")
  colo<-c("black","red")
  main_title<-paste("GDP shifted  by ",h," quarters",sep="")
  plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
  for (i in 1:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
  }
  abline(h=0)
  axis(1,at=c(1,12*1:(nrow(mplot)/12)),labels=rownames(mplot)[c(1,12*1:(nrow(mplot)/12))])
  axis(2)
      if (h==0)
    legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

  box()
}
dev.off()

# Plot of direct forecasts without Pandemic, only financial crisis
file = "./Figures/direct_wc_financial_crisis.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7.5, height = 6)

par(mfrow=c(2,2))
for (h in 0:3)
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected indicators on forward-shifted BIP: start at t=L (same sample as HP-C)
  lm_obj<-lm(forward_shifted_BIP[L:length(forward_shifted_BIP)]~x_mat_wc[L:nrow(x_mat_wc),select_direct_indicator])
  # You will probably not find statistically significant regressors for h>2: BIP is a noisy series
  sum_obj<-summary(lm_obj)
  sum_obj$fstatistic  
  # Technical note: 
  # -Residuals are subject to heteroscedasticity (crises) and autocorrelation
  # -Therefore classic OLS tests for statistical significance are biased
  # -We shall rely on HAC-adjusted p-values further down (R-package sandwich)
  
  # Compute the predictor: one can rely on the generic R-function predict or compute the predictor manually
  direct_forecast<-lm_obj$coef[1]+x_mat_wc[,select_direct_indicator]%*%lm_obj$coef[2:(length(select_direct_indicator)+1)]
  # Note that this is a full-sample predictor (no out-of-sample span)
  
  # We can now plot target and direct forecast: for h>2 the predictor comes close to a flat line centered at zero
  mplot<-cbind(forward_shifted_BIP,direct_forecast)
  rownames(mplot)<-rownames(x_mat_wc)
  mplot<-mplot[which(rownames(mplot)>2008&rownames(mplot)<2011),]
  colnames(mplot)<-c("GDP","Direct forecast")
  colo<-c("black","red")
  main_title<-paste("GDP shifted forward by ",h," quarters",sep="")
  plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
  for (i in 1:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
#    if (h==0)
#    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
  abline(h=0)
  axis(1,at=1:nrow(mplot),labels=rownames(mplot))
  axis(2)
    if (h==0)
    legend("bottomright", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

  box()
}
dev.off()


@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/direct_wc_all.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=5in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{Direct forecasts (red lines) based on all indicators and full sample information, without the pandemic: GDP (black line) shifted by zero one, two and three quarters.", sep = "")
cat("\\label{direct_wc}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/direct_wc_financial_crisis.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=5in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{Direct forecast  across the financial crisis:  regression based on all indicators and full sample information, without the pandemic.", sep = "")
cat("\\label{direct_wc_financial_crisis}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
The results indicate that as $h$ increases, the peaks and dips of the direct forecasts become increasingly right-shifted (delayed) relative to the target. Additionally, the F-statistics precipitously decline from $F=\Sexpr{round(f_vec_unfiltered[3],2)}$, for $h=2$, to $F=\Sexpr{round(f_vec_unfiltered[4],2)}$, for $h=3$, see Table \eqref{f_stat}, suggesting that the predictor becomes statistically insignificant for larger forecast horizons exceeding two quarters (link to Heinisch and Scheufele).   


\subsection{Filter: HP(160)}

As shown, the performance of direct forecasts sharply declines for larger forecast horizons. We conjecture that erratic short-term fluctuations -—unpredictable high-frequency noise -— overlay the data, thereby obscuring the effective 'signal' and making a direct regression more susceptible to overfitting. We therefore envisage to highlight the signal by applying a filter to dampen high-frequency noise. 
The so-called Hodrick-Prescott filter is a classic tool used in business cycle analysis: the filter is specified by a single smoothing parameter $\lambda$ and the value $\lambda=1600$ is specifically recommended for quarterly data. However, Phillips and Jin (2021) suggest that the HP(1600) filter removes relevant information due to excessive smoothing.  In our context, this oversmoothing issue would be further exacerbated when considering forecast horizons shorter than a year -—an interval inconsistent with the mean duration of up to several years of business cycles, as highlighted by the HP(1600). Consequently, we here select a more adaptive HP(160) 'target' filter. 
While this choice may appear somewhat arbitrary, an analysis of the filter in the frequency domain confirms a more suitable profile for the corresponding amplitude function, assigning greater weight to yearly components -—relevant in our prediction framework-— than the classic quarterly HP filter. This approach also addresses and controls for undesirable high-frequency noise. See Fig. \ref{hp_160}, which presents both two-sided and (classic) one-sided filters (top panels) along with the associated amplitude functions (bottom panels). We now posit the HP(160) filter as a means to achieve better forecasting performance at larger horizons, noting that a comprehensive technical analysis of the effect of $\lambda$ on the resulting BIP predictor can be conducted using the M-SSA package. 
<<label=init,results=hide>>=
# Section 3.2: HP filter

# Target filter: lambda_HP is the single most important hyperparameter, see tutorial 7.1 for a discussion
lambda_HP<-160
# Filter length: nearly 8 years is fine for the selected lambda_HP (filter weights decay sufficiently fast)
#   The length should be an odd number (see tutorial 7.1)
L<-31
HP_obj<-HP_target_mse_modified_gap(L,lambda_HP)
# Classic concurrent (one-sided) HP filter


file = "./Figures/hp_160.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7.5, height = 6)
par(mfrow=c(2,2))
hp_two<-c(HP_obj$hp_mse[L:2],HP_obj$hp_mse)
ts.plot(hp_two,main=paste("Two-sided HP(",lambda_HP,")",sep=""),xlab="",ylab="")
hp_c<-HP_obj$hp_trend
ts.plot(hp_c,main="One-sided (concurrent) HP-C",xlab="",ylab="")

# Analyze filter in frequency-domain (amplitude function)
# Specify the number of equidistant frequency ordinates in [0,pi]
K<-600
# Compute transfer, amplitude and shift functions (shift=phase divided by frequency)
amp_obj_hp_c<-amp_shift_func(K,hp_two,F)
  
# Plot amplitude function
mplot<-matrix(amp_obj_hp_c$amp,ncol=1)
colnames(mplot)<-paste("Concurrent HP, lambda=",lambda_HP,sep="")
colo<-c("blue",rainbow(ncol(mplot)))
plot(mplot[,1],type="l",axes=F,xlab="Frequency",ylab="",main=paste("Amplitude HP(",lambda_HP,")",sep=""),ylim=c(min(mplot),max(mplot)),col=colo[1])
if (ncol(mplot)>1)
{
  lines(mplot[,2],col=colo[2])
  abline(v=which(mplot[,1]==max(mplot[,1])),col=colo[1])
  mtext(colnames(mplot)[1],line=-1,col=colo[1])
    
  for (i in 2:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
}
axis(1,at=1+0:4*K/4,labels=expression(0, pi/4, 2*pi/4,3*pi/4,pi))
axis(2)
box()
K<-600
# Compute transfer, amplitude and shift functions (shift=phase divided by frequency)
amp_obj_hp_c<-amp_shift_func(K,hp_c,F)
  
# Plot amplitude function
mplot<-matrix(amp_obj_hp_c$amp,ncol=1)
colnames(mplot)<-paste("Concurrent HP, lambda=",lambda_HP,sep="")
colo<-c("blue",rainbow(ncol(mplot)))
plot(mplot[,1],type="l",axes=F,xlab="Frequency",ylab="",main="Amplitude HP-C",ylim=c(0,max(mplot)),col=colo[1])
if (ncol(mplot)>1)
{
  lines(mplot[,2],col=colo[2])
  abline(v=which(mplot[,1]==max(mplot[,1])),col=colo[1])
  mtext(colnames(mplot)[1],line=-1,col=colo[1])
    
  for (i in 2:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
}
abline(h=0)
axis(1,at=1+0:4*K/4,labels=expression(0, pi/4, 2*pi/4,3*pi/4,pi))
axis(2)
box()
dev.off()


@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/hp_160.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=5in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{Two-sided HP-160) (top left) and one-sided (concurrent) HP-C filters (top right) with corresponding amplitude functions (bottom).", sep = "")
cat("\\label{hp_160}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@

\subsection{Direct HP Forecast}\label{hpdf}


Extending the `classic' direct forecast design, we here consider filtered indicators, based on the one-sided HP(160), denoted as HP-C: the filtered indicators are explanatory variables for the regressions on forward-shifted BIP\footnote{Katja and Simon: for each forecast horizon $h=0,1,2,3$ I'm using corresponding forecasts of the real-time filter output, assuming the data to be white noise (assuming an ARMA model does not lead to significantly different results). I think we might ignore these technical details in the paper.}. As in the previous section, we rely on all indicators as well as the full sample estimate for illustration, see Figs.\eqref{direct_hp_forecasts} (all observations with exclusion of the pandemic) and \eqref{direct_hp_forecasts_financial_crisis} (financial crisis). A comparison with the classic direct forecasts in Fig.\eqref{direct_wc_financial_crisis} indicates that the new predictors are slightly less retarded (`faster'). 
<<label=init,results=hide>>=
# Section 3.3: HP-filtered data used in regression on future BIP

# Compute filter outputs for forecast horizons 0:6, assuming WN data
# Forecast horizons
# Without Pandemic
h_vec<-0:6
hp_c_array_wc<-array(dim=c(ncol(x_mat),nrow(x_mat_wc),length(h_vec)))
for (j in 1:length(h_vec))
{
  for (i in 1:ncol(x_mat))
  {
# For forecast horizon h_vec[j], the first h_vec[j] filter coefficients are skipped (zeroes are appended at 
#     the end). 
#   -This simple rule is optimal if the data is (close to) WN (white noise).
#   -Log-returns of the indicators are fairly close to WN (one can inspect the ACFs) 
    hp_c_forecast<-c(hp_c[(h_vec[j]+1):L],rep(0,h_vec[j]))
    hp_c_array_wc[i,,j]<-filter(x_mat_wc[,i],hp_c_forecast,side=1)
  }
}
dimnames(hp_c_array_wc)[[1]]<-colnames(x_mat_wc)
dimnames(hp_c_array_wc)[[2]]<-rownames(x_mat_wc)
dimnames(hp_c_array_wc)[[3]]<-paste("h=",h_vec,sep="")

# Same but data with Pandemic
h_vec<-0:6
hp_c_array<-array(dim=c(ncol(x_mat),nrow(x_mat),length(h_vec)))
for (j in 1:length(h_vec))
{
  for (i in 1:ncol(x_mat))
  {
# For forecast horizon h_vec[j], the first h_vec[j] filter coefficients are skipped (zeroes are appended at 
#     the end). 
#   -This simple rule is optimal if the data is (close to) WN (white noise).
#   -Log-returns of the indicators are fairly close to WN (one can inspect the ACFs) 
    hp_c_forecast<-c(hp_c[(h_vec[j]+1):L],rep(0,h_vec[j]))
    hp_c_array[i,,j]<-filter(x_mat[,i],hp_c_forecast,side=1)
  }
}
dimnames(hp_c_array)[[1]]<-colnames(x_mat)
dimnames(hp_c_array)[[2]]<-rownames(x_mat)
dimnames(hp_c_array)[[3]]<-paste("h=",h_vec,sep="")


# Compute and plot direct HP forecasts: full sample without pandemic
file = "./Figures/direct_hp_forecasts.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7.5, height = 6)

par(mfrow=c(2,2))
f_vec_hp<-t_mat_hp<-p_val_hp<-MSE_hp_vec<-NULL
for (h in 0:3)
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected filtered indicators on forward-shifted BIP
  length(forward_shifted_BIP)
  lm_obj<-lm(forward_shifted_BIP~t(hp_c_array_wc[,,1]))
  # You will probably not find statistically significant regressors for h>2: BIP is a noisy series
  sum_obj_hp<-summary(lm_obj)
  sum_obj<-summary(lm_obj)
  MSE_hp_vec<-c(MSE_hp_vec,sum_obj$sigma^2)
  # Technical note: 
  # -Residuals are subject to heteroscedasticity (crises) and autocorrelation
  # -Therefore classic OLS tests for statistical significance are biased
  # -We shall rely on HAC-adjusted p-values further down (R-package sandwich)
  
  # Compute the predictor: one can rely on the generic R-function predict or compute the predictor manually
  direct_hp_forecast<-lm_obj$coef[1]+t(hp_c_array_wc[,,1])%*%lm_obj$coef[2:(ncol(t(hp_c_array_wc[,,1]))+1)]
  # Note that this is a full-sample predictor (no out-of-sample span)
  
  # We can now plot target and direct forecast: for h>2 the predictor comes close to a flat line centered at zero
  mplot<-cbind(forward_shifted_BIP,direct_hp_forecast)
  rownames(mplot)<-rownames(x_mat_wc)

  colnames(mplot)<-c("GDP","Direct forecast")
  colo<-c("black","blue")
  main_title<-paste("GDP shifted forward by ",h," quarters",sep="")
  plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
  for (i in 1:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
#    if (h==0)
#    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
  abline(h=0)
  axis(1,at=1:nrow(mplot),labels=rownames(mplot))
  axis(2)
  if (h==0)
    legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

  box()
}
#colnames(t_mat_hp)<-select_vec_multi
#rownames(t_mat_hp)<-paste("h=",0:3)
dev.off()





# Same but financial crisis only
file = "./Figures/direct_hp_forecasts_financial_crisis.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7.5, height = 6)

par(mfrow=c(2,2))

for (h in 0:3)
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected indicators on forward-shifted BIP
  length(forward_shifted_BIP)
  lm_obj<-lm(forward_shifted_BIP~t(hp_c_array_wc[,,1]))
  # You will probably not find statistically significant regressors for h>2: BIP is a noisy series
  sum_obj<-summary(lm_obj)
  sum_obj$fstatistic  
  # Technical note: 
  # -Residuals are subject to heteroscedasticity (crises) and autocorrelation
  # -Therefore classic OLS tests for statistical significance are biased
  # -We shall rely on HAC-adjusted p-values further down (R-package sandwich)
  
  # Compute the predictor: one can rely on the generic R-function predict or compute the predictor manually
  direct_hp_forecast<-lm_obj$coef[1]+t(hp_c_array_wc[,,1])%*%lm_obj$coef[2:(ncol(t(hp_c_array_wc[,,1]))+1)]
  # Note that this is a full-sample predictor (no out-of-sample span)
  
  
# Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected indicators on forward-shifted BIP
  lm_obj<-lm(forward_shifted_BIP~x_mat_wc[,select_direct_indicator])
  # You will probably not find statistically significant regressors for h>2: BIP is a noisy series
  sum_obj<-summary(lm_obj)
  sum_obj$fstatistic  
  # Technical note: 
  # -Residuals are subject to heteroscedasticity (crises) and autocorrelation
  # -Therefore classic OLS tests for statistical significance are biased
  # -We shall rely on HAC-adjusted p-values further down (R-package sandwich)
  
  # Compute the predictor: one can rely on the generic R-function predict or compute the predictor manually
  direct_forecast<-lm_obj$coef[1]+x_mat_wc[,select_direct_indicator]%*%lm_obj$coef[2:(length(select_direct_indicator)+1)]

  
  
  # We can now plot target and direct forecast: for h>2 the predictor comes close to a flat line centered at zero
  mplot<-cbind(forward_shifted_BIP,direct_hp_forecast,direct_forecast)
    rownames(mplot)<-rownames(x_mat_wc)

  mplot<-mplot[which(rownames(mplot)>2007&rownames(mplot)<2010),]
  colnames(mplot)<-c("GDP","Direct HP forecast","Direct forecast")
  
  colo<-c("black","blue","red")
  main_title<-paste("GDP shifted forward by ",h," quarters",sep="")
  plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
  for (i in 1:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
#    if (h==0)
#    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
  abline(h=0)
  axis(1,at=1:nrow(mplot),labels=rownames(mplot))
  axis(2)
  if (h==0)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
  box()
}

dev.off()

#-------------------
# Compute p-values of direct and HP-c forecasts: rely on HAC adjusted Wald-statistic
# -There is no HAC-adjustment for F-statistic
# -Use Wald-test with HAC-adjusted variance of estimators

ws_vec_unfiltered<-f_vec_unfiltered<-p_val_unfiltered<-MSE_unfiltered_vec<-NULL
for (h in 0:6)#h<-0
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected indicators on forward-shifted BIP: start at t=L (same sample as HP-C)
  lm_obj<-lm(forward_shifted_BIP[L:length(forward_shifted_BIP)]~x_mat_wc[L:nrow(x_mat_wc),])
# HAC adjustment
  var_HAC<-vcovHAC(lm_obj)
  coef<-lm_obj$coef
# Wald statistic  
  chisq<-t(coef)%*%solve(var_HAC)%*%coef
# P-Value  
  ws_vec_unfiltered<-c(ws_vec_unfiltered,pchisq(chisq,ncol(x_mat_wc)+1,lower.tail = F))
}



ws_vec_hp<-f_vec_hp<-t_mat_hp<-p_val_hp<-MSE_hp_vec<-NULL
for (h in 0:6)#h<-3
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat_wc[(1+lag_vec[1]+h):nrow(x_mat_wc),"BIP"],rep(NA,h+lag_vec[1]))
  # Regress selected filtered indicators on forward-shifted BIP
  length(forward_shifted_BIP)
  lm_obj<-lm(forward_shifted_BIP~t(hp_c_array_wc[,,1]))
# HAC adjustment  
  var_HAC<-vcovHAC(lm_obj)
  coef<-lm_obj$coef
# Wald statistic  
  chisq<-t(coef)%*%solve(var_HAC)%*%coef
# P-value  
  ws_vec_hp<-c(ws_vec_hp,pchisq(chisq,ncol(x_mat_wc)+1,lower.tail = F))
  
}


@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/direct_hp_forecasts.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=5in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{Direct HP forecasts: entire data set with exclusion of the pandemic.", sep = "")
cat("\\label{direct_hp_forecasts}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/direct_hp_forecasts_financial_crisis.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=5in, width=6in]{", file, "}\n",sep = "")
cat("\\caption{Shifted GDP (black), direct HP forecast (blue) and classic direct forecast (red) over the curse of the financial crisis:  regression based on all indicators and full sample information (without pandemic).", sep = "")
cat("\\label{direct_hp_forecasts_financial_crisis}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
Moreover, the F-statistics are larger than for the direct forecasts, see Table \eqref{f_stat}, but the predictor remains statistically insignificant at forecast horizons exceeding two quarters (even though the evaluation is conducted in-sample and based on all available indicators). 






<<label=ats_mba_2,echo=FALSE,results=tex>>=

mat1<-rbind(round(ws_vec_hp,5),round(ws_vec_unfiltered,5))
colnames(mat1)<-paste("h=",0:(length(ws_vec_unfiltered)-1))
rownames(mat1)<-c("HP-C filtered","Unfiltered")
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("Statistical significance of unfiltered and HP-C filtered forecasts based on HAC-adjusted Wald test: all indicators and full sample (without pandemic).  "),
label=paste("f_stat",sep=""),
center = "centering", file = "", floating = FALSE)
@

We now propose a more refined causal filter design aiming for statistical significance of the resulting predictor at longer forecast horizons, out-of-sample.   




\section{Multivariate Causal Filter: M-SSA}

The application of the one-sided HP-C filter to the indicators has demonstrated improvements in forecast performance. However, the univariate nature of this filter limits its ability to leverage information from the cross-section, as supported by leading indicators. Additionally, the noise suppression capability of the one-sided filter is compromised, as illustrated by high-frequency leakage of the amplitude function in Fig. \eqref{hp_160} and further elaborated upon by Wildi (2025). To address these limitations, we propose an extension of the Smooth Sign Accuracy (SSA) framework introduced by Wildi (2025).


\subsection{Optimization criterion}



Let $\mathbf{X}_t$ (of dimension $t\times n$) denote a set of $n$ explanatory series $\mathbf{x}_{1t},...,\mathbf{x}_{nt}$, with observations $\mathbf{x}_{it}=(x_{i1},...,x_{it})'$. Let $\mathbf{z}_t=(z_{1},...,z_t)$  denote a target series, which typically lies outside the linear space spanned by $\mathbf{X}_t$  (and is unknown at time $t$). For simplicity, we assume stationarity of all time series involved. In this framework, $\mathbf{X}_t$ corresponds to a matrix of selected economic indicators with $n=\Sexpr{length(select_vec_multi)}$, and $z_{it}$   is the output of a two-sided HP(160) filter applied to the $i$-th indicator, $i=1,...,\Sexpr{length(select_vec_multi)}$. Since $z_{it}$  depends on future observations $x_{it+1},x_{it+2},...$, the prediction task involves `tracking' $z_{it}$  using the estimate $y^i_{t}=\sum_{j=1}^ny^i_{jt}$, where $y^i_{jt}=\mathbf{b}^i_j~'\mathbf{x}_{jt}=\sum_{k=0}^{L} b^i_{jk}x_{jk}$ are the outputs of a multivariate (causal or one-sided) filter $\mathbf{B}^i$, with columns $\mathbf{b}^i_{j}$ of fixed length $L$, $j=1,...,\Sexpr{length(select_vec_multi)}$, assigning weight to the last $L$ observations of the $j$-th indicator $\mathbf{x}_{jt}$ (the fixed-length assumption is merely used for ease of exposition).
For the sake of clarity, we now omit the upper-case index  $i$ for all variables, assuming $z_t=z^{i_0}_{t}$ for some fixed $i_0$.% Additionally, we assume a fixed filter length $L$, such that $\mathbf{B}^i_t=\mathbf{B}_t=\mathbf{B}$, which has dimension $L\times \Sexpr{length(select_vec_multi)}$. 
The task of `tracking'  a target can be formalized in different ways; here, we focus on the target correlation $\rho(z,y,h)$ between $y_t$ and $z_{t+h}$, where $h\geq 0$ denotes the forecast horizon (backcasting with $h<0$ is ignored in this context). To streamline the notation and avoid unnecessary complexity, we assume a fixed horizon, say $h=h_0$, so that we may drop the reference to $h$ in our notation. In the univariate case ($n=1$), Wildi (2025) proposes the Simple Sign Accuracy (SSA) as an optimization criterion for this task:
\begin{eqnarray}\label{critssa}
\left.\begin{array}{c}\rho(z,y)\to\max\\
\rho(y,1)=\rho_1\end{array}\right\}.
\end{eqnarray}
Objective function and constraint are expressed in terms of correlations, namely the target correlation $\rho(z,y)$ between target and predictor and the lag-one autocorrelation $\rho(y,1)$ of the predictor. The parameter $\rho_1$ governs the smoothness of the predictor: higher values of $\rho_1$ generally promote smoother trajectories of $y_t$. Formally, assuming that the process $x_t$ is centered (zero-mean), Wildi (2024) establishes a connection between $\rho(y,1)$ and the expected duration between consecutive zero-crossings (sign changes) of $y_t$, the so-called holding time, denoted by $ht(y)$:
\begin{eqnarray*}\label{ht}
ht(y)=\frac{\pi}{\arccos(\rho(y,1))}.
\end{eqnarray*}
Since the non-linear transformation involved is strictly monotonic, the SSA criterion can be reformulated as the optimization problem:
\begin{eqnarray}\label{critssaht}
\left.\begin{array}{c}\rho(z,y)\to\max\\
\frac{\arccos(\rho(y,1))}{\pi}=1/ht_1\end{array}\right\},
\end{eqnarray}
where the smoothness parameter $1/ht_1$ expresses the rate of zero-crossings of the predictor\footnote{Formally, the exact relationship between the zero-crossing rate and the lag-one autocorrelation of the predictor assumes Gaussian time series, but Wildi (2024) demonstrates robustness to deviations from this assumption.}. \\


We now briefly discuss some implications of criterion \eqref{critssaht}. First, the objective function is indifferent to an affine transformation of the predictor. This ambiguity can be resolved by assuming an arbitrary scale and level for $y_t$ (standardization). Alternatively, a mean-square error norm (MSE) may be substituted for the target correlation, as noted in Wildi (2025). In this case, the classic MSE predictor $y_{t,MSE}$ is obtained as a solution to the SSA criterion by insertion of $1/ht_1:=1/ht_{MSE}$ in the constraint, where $ht_{MSE}$ represents the holding time of $y_{t,MSE}$. %If the MSE predictor is noisy, which is often the case in applications, one can select $ht_1>ht_{MSE}$  in the constraint to address the rate of noisy crossings or false alarms. 
Second, the concept can be extended to a multivariate framework, denoted as M-SSA, by generalizing the correlation functions, as detailed in Wildi (2025b). Lastly, sign changes in trend growth, represented by zero-crossings of the target $z_t$, are indicative of relevant changes in the trajectory of the economy, for example at transitions between expansions and recessions. Unfortunately, classic predictors often generate excessively many false `noisy' crossings, due to high-frequency leakage as illustrated by the amplitude function in Fig. \eqref{hp_160} (bottom right panel) and further elaborated upon by Wildi (2025). The SSA criterion helps control this phenomenon. More precisely, Wildi (2025) derives an equivalent dual formulation of criterion \eqref{critssaht}, which distinguishes the SSA solution as exhibiting the smallest rate of zero-crossings of any (linear) predictor with the same target correlation. We now rely on the M-SSA criterion to derive a `smooth' predictor $y_t$ of $z_t$. %In a second stage, serving as a generalization and refinement of the univariate HP-C utilized in the direct HP forecast.


\subsection{M-MSE and M-SSA Nowcasts}

For illustration, we consider a nowcast of the target $z_t$ generated by the output of the two-sided HP(160) filter applied to BIP, which we denote by HP-BIP. We compare the classic multivariate mean squared error (MSE) predictor, denoted by M-MSE, with the M-SSA predictor, where we set $ht_1=1.5ht_{MSE}$ in the holding time constraint. This configuration ensures that the M-SSA predictor produces approximately 33$\%$ fewer zero-crossings than M-MSE over the long term. The purpose of this constraint is to compare the effect of a different level of smoothness on the prediction performance (target correlation). The estimation of the underlying VAR(1) model employed for the M-MSE and M-SSA is based on data observations up to January 2008. This approach ensures a lengthy out-of-sample period that encompasses significant events such as the financial crisis, the sovereign debt crisis, and the COVID-19 pandemic. Further details and background information are available in Wildi (2025b). All computations are performed utilizing the M-SSA package, as documented in Wildi (2025b).\\
<<label=init,results=hide>>=
# Section 4.2: Nowcast M-SSA and M-MSE

# Compute and compare M-SSA and M-MSE nowcasts
h_vec<-0

# We rely on data with Pandemic
#   -M-SSA is not affected since the in-sample span ends in 2008
if (recompute_results)
{
# Run the wrapper, see tutorial 7.2
#   -The function computes M-SSA for each forecast horizon h in h_vec
  mssa_indicator_obj<-compute_mssa_BIP_predictors_func(x_mat,lambda_HP,L,date_to_fit,p,q,ht_mssa_vec,h_vec,f_excess,lag_vec,select_vec_multi)

# Replicate HT of HP-C
# Theoretical HT  
  ht_hp_c<-compute_holding_time_func(hp_c)$ht
# Sample HT: want to replicate sample HT in nowcast example and compare target correlations
  ht_hp_c<-8


  ht_mssa_vec_HP_C<-c(ht_hp_c,  6.738270,   7.232453,   7.225927,   7.033768)

  mssa_indicator_HP_HT_obj<-compute_mssa_BIP_predictors_func(x_mat,lambda_HP,L,date_to_fit,p,q,ht_mssa_vec_HP_C,h_vec,f_excess,lag_vec,select_vec_multi)

  save(mssa_indicator_obj,file=paste(path.result,"/nowcast_obj",sep=""))
  save(mssa_indicator_HP_HT_obj,file=paste(path.result,"/nowcast_HT_HP_obj",sep=""))
} else
{
  load(file=paste(path.result,"/nowcast_obj",sep=""))
  load(file=paste(path.result,"/nowcast_HT_HP_obj",sep=""))
}

# Select M-SSA output for BIP: tracks HP-BIP
select<-"BIP"

dim(mssa_indicator_obj$bk_x_array)
# Dimensions of bk_x_array:
# 1. Which series do we target: depending on the series various settings may be used (forecast excess)
# 2. The corresponding M-SSA components
# 3. L*length(select_vec): filter weights attributed to the indicators
# 4. Forecast horizon h
bk<-matrix(mssa_indicator_obj$bk_x_array[select,select,,"h=0"],nrow=L)
gammak<-matrix(mssa_indicator_obj$gammak_x_mse[select,select,,"h=0"],nrow=L)
colnames(bk)<-colnames(gammak)<-select_vec_multi


# Target series: output of two-sided HP applied to BIP: 
#   -The target is forward-shifted by the forecast horizon (plus publication lag)
target_shifted_mat<-mssa_indicator_obj$target_shifted_mat
# Original M-SSA predictor, see tutorial 7.3 (equal-weighting of M-SSA outputs)
#   -One predictor available for each forecast horizon in h_vec
predictor_mssa_mat<-mssa_indicator_obj$predictor_mssa_mat
# M-SSA components, see tutorial 7.2
#   -This is a three dimensional array
#   -For each forecast horizon and for each indicator we obtain the M-SSA predictor when targeting 
#     the two-sided HP applied to this indicator, see exercise 1.1 below
mssa_array<-mssa_indicator_obj$mssa_array
# M-MSE components
# -Same as mssa_array but without HT imposed, i.e., classic multivariate mean-square error signal extraction
# -Forecast performances, see exercise 5 below 
mmse_array<-mssa_indicator_obj$mmse_array

# Select M-SSA output of design replicating HT of HP-C
mssa_array_HT_HP_C<-mssa_indicator_HP_HT_obj$mssa_array
bk_HP_HP_C<-matrix(mssa_indicator_HP_HT_obj$bk_x_array[select,select,,"h=0"],nrow=L)
colnames(bk_HP_HP_C)<-select_vec_multi



file = "./Figures/bk_gammak.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7, height = 7)

par(mfrow=c(1,2))
colo<-c("black", "red", "green", "blue", "orange", "dimgray")
mplot<-gammak
colnames(mplot)[1]<-"GDP"
plot(mplot[,1],main="M-MSE",axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,1+5*1:(nrow(mplot)/5)),labels=c(0,5*1:(nrow(mplot)/5)))
axis(2)
legend("topright", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()

mplot<-bk
plot(mplot[,1],main="M-SSA",axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,1+5*1:(nrow(mplot)/5)),labels=c(0,5*1:(nrow(mplot)/5)))
axis(2)
box()
dev.off()






mssa<-t(mssa_array[,,1])
mmse<-t(mmse_array[,,1])
mssa_HT_HP_C<-t(mssa_array_HT_HP_C[,,1])

file = "./Figures/mssa_msse_now.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7, height = 7)

hp_c_out<-filter(x_mat[,select],hp_c,side=1)
par(mfrow=c(1,1))
#mplot<-scale(cbind(target_shifted_mat,hp_c_out,mssa[,select],mssa_HT_HP_C[,select],mmse[,select]))
#dim(mplot)
#colnames(mplot)<-c("Target: HP-BIP","HP-C","M-SSA smaller HT","M-SSA larger HT","M-MSE")
mplot<-scale(cbind(target_shifted_mat,mssa[,select],mmse[,select]))
dim(mplot)
colnames(mplot)<-c("Target: HP-GDP","M-SSA","M-MSE")

rownames(mplot)<-rownames(x_mat)
mplot<-mplot[L:nrow(mplot),]
colo<-c("black","violet","blue","orange","green")
colo<-c("black","blue","green")
main_title<-"Nowcasting HP-GDP"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
  mtext(colnames(mplot)[i],col=colo[i],line=-i)
}
abline(h=0)
abline(v=which(rownames(mplot)>date_to_fit)[1],lty=2,lwd=2)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
box()

dev.off()


mat_cor_ht<-rbind(c(cor(na.exclude(mplot[,c("Target: HP-GDP","M-SSA")]))[1,2],
cor(na.exclude(mplot[,c("Target: HP-GDP","M-MSE")]))[1,2]),
c(compute_empirical_ht_func(na.exclude(mssa[,select]))$empirical_ht,
compute_empirical_ht_func(na.exclude(mmse[,select]))$empirical_ht))

colnames(mat_cor_ht)<-c("M-SSA","M-MSE")
rownames(mat_cor_ht)<-c("Target correlation","HT")
# Keep M-MSE and M-SSA only


@

Figure \ref{bk_gammak} displays the coefficients of the multivariate nowcasts, where increased smoothing achieved through the M-SSA method manifests as a distinct pattern in the filter weights, notably influencing the rate of decay across increasing lags. The resulting filtered series, presented in Figure \ref{mssa_msse_now}, are standardized to enable direct comparisons. The M-SSA nowcast adheres to the specified constraint, exhibiting approximately one-third fewer zero-crossings than the M-MSE, confirming the effectiveness of the smoothness control imposed during the design. This is further corroborated by Table \ref{corhtnow}, which reports empirical holding times and target correlations. Increased smoothness achieved by the M-SSA comes at the cost of a slight reduction in tracking accuracy, as indicated by a marginally lower target correlation. This highlights the inherent trade-off—often referred to as the prediction dilemma—between smoothness (zero-crossing rate) and predictive accuracy (target correlation) within the M-SSA criterion.
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/bk_gammak.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=5in]{", file, "}\n",sep = "")
cat("\\caption{Multivariate M-MSE (left) and M-SSA  (right) nowcast filters.", sep = "")
cat("\\label{bk_gammak}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/mssa_msse_now.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=4in, width=5.5in]{", file, "}\n",sep = "")
cat("\\caption{Two-sided HP(160) applied to GDP (target, black) and nowcasts:  M-SSA (blue) and  M-MSE (green). The dashed vertical line delimits in- and out-of-sample spans. The two-sided filter does not extend to the sample end.", sep = "")
cat("\\label{mssa_msse_now}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=ats_mba_2,echo=FALSE,results=tex>>=
mat1<-round(mat_cor_ht,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(2,dim(mat1)[2]+1),
paste("Sample target correlations and HTs of M-SSA and M-MSE nowcasts.  "),
label=paste("corhtnow",sep=""),
center = "centering", file = "", floating = FALSE)
@
The results validate that the smoothing constraint incorporated into the multivariate extension of Criterion \eqref{critssa} effectively manages the zero-crossings of the predictor: sample estimates of the holding times (HTs) align with the expected values derived from Equation \eqref{ht}\footnote{Effective convergence of sample estimates to their theoretical expected values —assuming the true data-generating process is known— can be validated using the M-SSA package. This validation is typically performed through analyses of very long samples of simulated (multivariate) data, ensuring the consistency of the estimation procedures under idealized conditions.}. An increase of $50\%$ in the HT relative to the M-MSE predictor has only a modest effect on the target correlation, suggesting that this tradeoff could be beneficial in our application. Going forward, we now omit the M-MSE, as it is a special case of the more general M-SSA framework.


\subsection{M-SSA Forecasts}

The previously described nowcast example can be systematically extended to generate forecasts of the target variable. This extension utilizes the same empirical framework, incorporating an assumed $50\%$ increase in the HT over the M-MSE, and considers forward shifts of $h=0,...,6$  quarters of HP-BIP (note that M-SSA does not target BIP explicitly). %This approach facilitates the assessment of forecast performance across multiple horizons within the established methodological context. 
The influence of the forecast horizon on the M-SSA design is depicted in Fig. \eqref{bk_h}, which contrasts nowcast and one-year-ahead forecast: as $h$ increases (right panel), the scaling factor diminishes (zero-shrinkage), attributable to increased forecast uncertainty, and there is a relative amplification of the influence of the relevant indicators, leading BIP in relative terms.Additionally, a phase shift associated with the filter applied to BIP is observed (red line, right panel), reflecting the cyclical characteristics inherent to the HP filter. While this phase effect might cause an effective sign change in the BIP filter output as $h$ increases—something to be avoided in this context—the low-pass filters assigned to the additional 'leading' indicators (green and violet lines, right panel) continue to effectively track the low-frequency components of HP-BIP. The combination of the phase effect, applied to BIP, and level-tracking through these additional indicators enables more refined and effective tracking of the target compared to univariate forecasts, which rely solely on the phase-effect of the filter to look ahead of time.\\

M-SSA predictors are compared to the traditional univariate HP-C in Figs. \eqref{multivar_vs_univar} and \eqref{mssa_hpc_financial_crisis}. In the first figure, we compare both filters across the periods of the financial crisis (top panels) and the COVID-19 pandemic (bottom panels), for forecast horizons $h=0,...,6$. The nowcast from the previous section is included for reference. In the second figure we compare both filters to the forward-shifted BIP for shifts larger than two quarters. All series are standardized to facilitate visual comparison. The primary distinction of the M-SSA approach is the progressive left-shift of the predictor as a function of $h$; this shift becomes more pronounced with increasing $h$ and appears to be consistent across all levels, including the peaks and troughs of the series. Conversely, the positions of peaks and troughs in the HP-C series appear to remain largely unaffected by variations in $h$. The more pronounced and systematic left-shift observed in the M-SSA forecasts can be partly attributed to the increasing weight assigned to the additional indicators leading BIP, which dominate the BIP component at larger forecast horizons. %In comparison, the effect of phase shifts—arising from the cyclical nature of the HP-filter and manifesting in the HP-C forecasts (shown in the left panels)—seems less systematic. 
<<label=init,results=hide>>=
# Section 4.3: M-SSA forecasts
# Forecast horizons: M-SSA is optimized for each forecast horizon in h_vec 
h_vec<-0:6

if (recompute_results)
{
# Run the wrapper, see tutorial 7.2
#   -The function computes M-SSA for each forecast horizon h in h_vec
  mssa_indicator_obj<-compute_mssa_BIP_predictors_func(x_mat,lambda_HP,L,date_to_fit,p,q,ht_mssa_vec,h_vec,f_excess,lag_vec,select_vec_multi)
# Without pandemic  
  mssa_indicator_obj_wc<-compute_mssa_BIP_predictors_func(x_mat_wc,lambda_HP,L,date_to_fit,p,q,ht_mssa_vec,h_vec,f_excess,lag_vec,select_vec_multi)

  save(mssa_indicator_obj,file=paste(path.result,"/mssa_indicator_obj",sep=""))
  save(mssa_indicator_obj_wc,file=paste(path.result,"/mssa_indicator_obj_wc",sep=""))
} else
{
  load(file=paste(path.result,"/mssa_indicator_obj",sep=""))
  load(file=paste(path.result,"/mssa_indicator_obj_wc",sep=""))
}
# Target series: output of two-sided HP applied to BIP: 
#   -This is the target for which the original M-SSA predictor (tutorial 7.3) has been designed
#   -The target is forward-shifted by the forecast horizon (plus publication lag)
target_shifted_mat<-mssa_indicator_obj$target_shifted_mat
# Original M-SSA predictor, see tutorial 7.3
#   -One predictor available for each forecast horizon in h_vec
predictor_mssa_mat<-mssa_indicator_obj$predictor_mssa_mat
# M-SSA components, see tutorial 7.2
#   -This is a three dimensional array
#   -For each forecast horizon and for each indicator we obtain the M-SSA predictor when targeting 
#     the two-sided HP applied to this indicator, see exercise 1.1 below
mssa_array<-mssa_indicator_obj$mssa_array
# Same but M-MSE
mmse_array<-mssa_indicator_obj$mmse_array

# M-SSA outputs targeting HP-BIP at forecasts horizons h=0,...,6
mssa_array["BIP",,]

dim(mssa_indicator_obj$bk_x_array)
# Dimensions of bk_x_array:
# 1. Which series do we target: depending on the series various settings may be used (forecast excess)
# 2. The corresponding M-SSA components
# 3. L*length(select_vec): filter weights attributed to the indicators for each target
# 4. Forecast horizon h
select<-"BIP"
bk<-matrix(mssa_indicator_obj$bk_x_array[select,select,,"h=0"],nrow=L)
gammak<-matrix(mssa_indicator_obj$gammak_x_mse[select,select,,"h=0"],nrow=L)
colnames(bk)<-colnames(gammak)<-select_vec_multi


file = "./Figures/bk_h.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 8, height = 6)

par(mfrow=c(1,2))
colo<-c("black", "red", "green", "blue", "orange", "dimgray")
mplot<-bk
colnames(mplot)[1]<-"GDP"
plot(mplot[,1],main="M-SSA: h=0",axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,1+5*1:(nrow(mplot)/5)),labels=c(0,5*1:(nrow(mplot)/5)))
axis(2)
legend("topright", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()

bk<-matrix(mssa_indicator_obj$bk_x_array[select,select,,"h=4"],nrow=L)
colnames(bk)<-colnames(gammak)<-select_vec_multi
mplot<-bk
plot(mplot[,1],main="M-SSA: h=4",axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=c(1,1+5*1:(nrow(mplot)/5)),labels=c(0,5*1:(nrow(mplot)/5)))
axis(2)
box()

dev.off()









file = "./Figures/multivar_vs_univar.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 8, height = 8)

# Select BIP
i<-1
# HP-C Financial crisis
mplot<-scale(hp_c_array[i,,])
colnames(mplot)<-paste("h=",h_vec,sep="")
par(mfrow=c(2,2))
colo<-c(rainbow(ncol(mplot)))
mplot<-mplot[which(rownames(mplot)>2007&rownames(mplot)<2011),]
main_title<-paste("HP-C targeting HP-",colnames(x_mat)[i],sep="")
main_title<-"HP-C: financial crisis"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (j in 1:ncol(mplot))
{
  lines(mplot[,j],col=colo[j],lwd=1,lty=1)
#  mtext(colnames(mplot)[j],col=colo[j],line=-j)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=rownames(mplot))
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()



# HP-C Pandemic
mplot<-scale(hp_c_array[i,,])
colnames(mplot)<-paste("HP-",colnames(x_mat)[i],": h=",h_vec,sep="")
colo<-c(rainbow(ncol(mplot)))
mplot<-mplot[which(rownames(mplot)>2017&rownames(mplot)<2022),]
main_title<-paste("HP-C targeting HP-",colnames(x_mat)[i],sep="")
main_title<-"HP-C: pandemic"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (j in 1:ncol(mplot))
{
  lines(mplot[,j],col=colo[j],lwd=1,lty=1)
#  mtext(colnames(mplot)[j],col=colo[j],line=-j)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=rownames(mplot))
axis(2)
box()

# M-SSA financial crisis 
mplot<-scale(mssa_array[i,,])
colnames(mplot)<-paste("HP-",colnames(x_mat)[i],": h=",h_vec,sep="")
mplot<-mplot[which(rownames(mplot)>2007&rownames(mplot)<2011),]

colo<-c(rainbow(ncol(mplot)))
main_title<-paste("M-SSA targeting HP-",colnames(x_mat)[i],sep="")
main_title<-"MSSA: financial crisis"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (j in 1:ncol(mplot))
{
  lines(mplot[,j],col=colo[j],lwd=1,lty=1)
#  mtext(colnames(mplot)[j],col=colo[j],line=-j)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=rownames(mplot))
axis(2)
box()

# M-SSA: pandemic 
mplot<-scale(mssa_array[i,,])
colnames(mplot)<-paste("HP-",colnames(x_mat)[i],": h=",h_vec,sep="")
mplot<-mplot[which(rownames(mplot)>2017&rownames(mplot)<2022),]

colo<-c(rainbow(ncol(mplot)))
main_title<-paste("M-SSA targeting HP-",colnames(x_mat)[i],sep="")
main_title<-"MSSA: pandemic"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (j in 1:ncol(mplot))
{
  lines(mplot[,j],col=colo[j],lwd=1,lty=1)
#  mtext(colnames(mplot)[j],col=colo[j],line=-j)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=rownames(mplot))
axis(2)
box()

dev.off()


# Plot of M-SSA and HP-C, only financial crisis
file = "./Figures/mssa_hpc_financial_crisis.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 8, height = 8)

par(mfrow=c(2,2))
for (h in 3:6)#h<-1
{
  # Shift BIP forward by publication lag+forecast horizon
  forward_shifted_BIP<-c(x_mat[(1+lag_vec[1]+h):nrow(x_mat),"BIP"],rep(NA,h+lag_vec[1]))

  # We can now plot target and direct forecast: for h>2 the predictor comes close to a flat line centered at zero
#  mplot<-scale(cbind(forward_shifted_BIP,hp_c_array_wc[select,,h+1],mssa_array_wc[select,,h+3]))
#  mplot<-scale(cbind(forward_shifted_BIP,hp_c_array_wc[select,,h+1],predictor_mssa_mat_wc[,h+3]))
  mplot<-scale(cbind(forward_shifted_BIP,mssa_array["BIP",,h+1],hp_c_array["BIP",,h+1]))
  rownames(mplot)<-rownames(x_mat)

  mplot<-mplot[which(rownames(mplot)>2006&rownames(mplot)<2011),]
  colnames(mplot)<-c("GDP","M-SSA","HP-C")
  colo<-c("black","blue","red")
  main_title<-paste("GDP shifted forward by ",h," quarters",sep="")
  plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
  for (i in 1:ncol(mplot))
  {
    lines(mplot[,i],col=colo[i])
#    mtext(colnames(mplot)[i],col=colo[i],line=-i)
  }
  abline(h=0)
  axis(1,at=1:nrow(mplot),labels=rownames(mplot))
  axis(2)
  if (h==3)
    legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

  box()
}
dev.off()



#----------------------------------------------------------------------------
# Section 5.1
# M-SSA predictor: for each forecast horizon h=0,...,6 this is the equally-weighted average of all M-SSA outputs
file = "./Figures/mssa_predictor.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)

par(mfrow=c(1,1))
mplot<-cbind(x_mat[,"BIP"],predictor_mssa_mat)
rownames(mplot)<-rownames(x_mat)
mplot<-mplot[L:nrow(mplot),]
colo<-c("black",rainbow(ncol(mplot)-1))
colnames(mplot)[1]<-"GDP"
main_title<-"Equally-weighted average of M-SSA outputs"
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (j in 1:ncol(mplot))
{
  lines(mplot[,j],col=colo[j],lwd=1,lty=1)
#  mtext(colnames(mplot)[j],col=colo[j],line=-j)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=rownames(mplot))
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

box()

dev.off()


file = "./Figures/mssa_predictor_interpretability.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)


j_now<-1
# Plot M-SSA nowcast and components
par(mfrow=c(1,1))
# Scale the data 
mplot<-scale(cbind(predictor_mssa_mat[,j_now],scale(t(mssa_array[,,j_now]))))
rownames(mplot)<-rownames(x_mat)
colnames(mplot)<-c(paste("M-SSA predictor optimized for h=",h_vec[j_now],sep=""),
                   paste("Subseries ",select_vec_multi,sep=""))
mplot<-mplot[L:nrow(mplot),]
colo<-c("blue","black", "red", "green", "blue", "orange", "dimgray")
colnames(mplot)[2]<-"Subseries GDP"

main_title<-c(paste("M-SSA predictor for h=",h_vec[j_now]," (solid blue) and sub-series (dashed lines)",sep=""),"In-sample span up to black vertical (dashed) line")
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=2,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=2)
#  mtext(colnames(mplot)[i],col=colo[i],line=-i)
}
abline(h=0)
abline(v=which(rownames(mplot)<=date_to_fit)[length(which(rownames(mplot)<=date_to_fit))],lwd=2,lty=2)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

box()
dev.off()



#------------------------------------------------------------
# Section 5.2


# Compute performances of original M-SSA predictor
#   -Predictor: equal weighting of all M-SSA components
#   -Target: two-sided HP applied to BIP (easier to forecast than BIP)

# Select start of out-of-sample span (entire financial crisis is out-of-sample)
in_out_separator<-"2007"
# We can specify the selection of macro-indicators for the direct forecast, see tutorial 7.3
#   Note: these results will not be used here (but we need to specify a selection anyway)
select_direct_indicator<-c("ifo_c","ESI")
perf_obj<-compute_perf_func(x_mat,target_shifted_mat,predictor_mssa_mat,predictor_mmse_mat,in_out_separator,select_direct_indicator,h_vec) 

# Regression on HP-BIP, without pandemic
p_value_HAC_HP_BIP_oos_wc<-perf_obj$p_value_HAC_HP_BIP_oos_wc

p_value_HAC_HP_BIP_oos_wc
# Strong significance
# Systematic pattern: minimal p-Values on diagonal of matrix
# Can predict low-frequency part of BIP


@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/bk_h.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=5.5in]{", file, "}\n",sep = "")
cat("\\caption{Multivariate M-SSA: $h=0$ (nowcast, left) and $h=4$ (one year forecast, right).", sep = "")
cat("\\label{bk_h}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/multivar_vs_univar.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=4in, width=5.5in]{", file, "}\n",sep = "")
cat("\\caption{Now- and forecasts of HP-GDP for $h=0,...,6$: HP-C (top) vs. M-SSA (bottom) across the financial crisis (left) and the pandemic (right).", sep = "")
cat("\\label{multivar_vs_univar}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@

<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/mssa_hpc_financial_crisis.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=4in, width=5.5in]{", file, "}\n",sep = "")
cat("\\caption{Forward-shifted GDP (black), M-SSA (blue) and HP-C (red) for $h=3,4,5,6$ across the financial crisis. All series are standardized for better visual inspection.", sep = "")
cat("\\label{mssa_hpc_financial_crisis}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@


\section{M-SSA Component Predictor}

The targets of the multivariate filters are the smoothed outputs obtained from the acausal two-sided HP(160) filter applied to the five indicators. However, our objective is to develop predictors that emphasize the unfiltered BIP. To achieve this, we can utilize the  M-SSA outputs, referred to as M-SSA components.




\subsection{Standardized Predictor: Equal-Weighting}


Assuming that all M-SSA components contribute equally to BIP prediction, an initial step involves averaging the standardized components to form an equally-weighted composite measure. Subsequently, the predictor is derived by regressing this standardized aggregate on the (forward-shifted) BIP series. Fig. \eqref{mssa_predictor} presents the BIP series alongside the equally-weighted M-SSA predictor. All series are standardized to facilitate visual comparison and to highlight the dynamic shifts, particularly the left-shift characteristic of the predictors.\\

To enhance interpretability and assessment of the M-SSA predictor, we propose analyzing its individual components. For illustration, Fig. \eqref{mssa_predictor_interpretability} shows the nowcast at $h=0$. The solid blue line (the nowcast) approaches the zero line near the end of the sample, with a recent upward movement mainly supported by the leading spread component. In contrast, the ifo- and ESI-components remain near the zero line, while the ip- and BIP-components appear to be awaiting additional evidence and confirmation before signaling a definitive movement.  This type of assessment can be useful for evaluating the relevance of recent changes in the forecasted time series dynamics.
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/mssa_predictor.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{BIP and equally-weighted M-SSA predictor: all series standardized.", sep = "")
cat("\\label{mssa_predictor}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/mssa_predictor_interpretability.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Equally-weighted M-SSA predictor and M-SSA components: all series standardized.", sep = "")
cat("\\label{mssa_predictor_interpretability}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@

%???Eventually add p-values and/rRMSEs???


\subsection{Tracking BIP: Optimal Weighting}


We now utilize the M-SSA components as regressors on forward-shifted BIP, extending the previous (standardized) equally-weighted M-SSA predictor to incorporate optimal weighting of the components. While we keep the M-SSA fixed, as based on data up to January 2008, we implement an expanding window starting from January 2007 for deriving the component weights, which are up-dated on a quarterly basis (this contrasts with Section \eqref{direct_forecast} which was based on the full sample information). \\


There are various combinations of M-SSA components for tracking BIP. For illustration, we here select the single BIP component resulting from the M-SSA filter tracking HP-BIP. Table \eqref{p_val_hpbip_wc} reports HAC-adjusted p-values from regressions of the out-of-sample predictor on HP-BIP, indicating a strong link between the predictor and the target, out-of-sample. 
<<label=ats_mba_2,echo=FALSE,results=tex>>=

shift_vec<-0:5

mat1<-round(p_value_HAC_HP_BIP_oos_wc,3)
rownames(mat1)<-paste("Shift=",shift_vec,sep="")
colnames(mat1)<-paste("h=",h_vec,sep="")
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("HAC adjusted p-values of regressions of BIP (M-SSA) component optimized for forecast horizons $h=0,...,6$  (the columns) on HP-BIP shifted forward by shift=0,...,5 (the rows). Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("p_val_hpbip_wc",sep=""),
center = "centering", file = "", floating = FALSE)
@
Our choice—focusing on the single M-SSA BIP component—emphasizes simplicity and interpretability, as future BIP and HP-BIP are connected through their shared low-frequency component. Additionally, the M-SSA BIP component is the most important predictor in the regression of the M-SSA outputs on BIP.  Finally, revisions due to quarterly updates of the regression equations are minimized by this predictor, and the estimates are more stable and robust over time\footnote{Other combinations can be experimented with using the M-SSA package. Regression weights of more complex designs, involving multiple components, tend to be more difficult to interpret due to the occurrence of negative weights and potential sign changes of the regressors over time, which may indicate overfitting or non-stationarity.} (see Section \eqref{revisions}). Note that information from the other  indicators is incorporated into the M-SSA BIP component through the multivariate filter design.\\



This setup allows us to evaluate the out-of-sample performance of various predictor approaches, including: (i) the simple mean of BIP, (ii) the direct forecast method described in Section \eqref{cdf}, (iii) the direct HP forecasts from Section \eqref{hpdf}, based on the univariate HP-C, and (iv) the new M-SSA BIP component predictor. %For completeness, we also consider an M-MSE component predictor derived from outputs of the multivariate MSE filter. 





\subsection{Out-of-Sample Forecast Performances}\label{oosp}


Tables \ref{p_val_wc} and \ref{rRMSE_mSSA_comp_mean_wc} present HAC-adjusted p-values and rRMSEs for the GDP component predictor. They are obtained from the simple regressions 

\begin{equation}
    \textrm{GDP}_{t+shift}=\beta_0(shift,h)+\beta_1(shift,h) \cdot \textrm{M-SSA}^{\textrm{GDP}}_t(h) + \epsilon_t^{shift,h}
    \label{eq:GDP_M-SSA}
\end{equation}

where $\textrm{M-SSA}^{\textrm{GDP}}_t(h)$ is the out-of-sample M-SSA predictor for GDP (not HP-GDP.)
%(in contrast to Table \ref{p_val_hpbip_wc}, which emphasized HP-GDP.) 
The p-values test $H_0 : 0 = \beta_1(shift,h)$ and do not account for potential bias or mis-scaling of the GDP predictor. In contrast, the rRMSEs, evaluated against the mean benchmark, incorporate eventual bias and mis-scaling effects. Additional results involving other predictor benchmarks are provided in the appendix, based on data sets with and without the pandemic. \\


The purposes of Equation \ref{eq:GDP_M-SSA} are twofold: first, the regression parameters enable affine transformations of the left-hand side variable, so that the standardized target $\textrm{GDP}_{t+shift}$ can be replaced by the original log-returns without affecting the p-values or rRMSEs reported in Tables \ref{p_val_wc} and \ref{rRMSE_mSSA_comp_mean_wc} (noting that the benchmark predictors, i.e., the direct forecasts and the arithmetic mean, similarly adjust to affine transformations); second, the static scale adjustment by $\beta_1(shift,h)$ compensates for the increasing zero-shrinkage of $\textrm{M-SSA}^{\textrm{GDP}}_t(h)$, reflecting greater uncertainty  as the forecast horizon $h$ increases. This simple transformation allows $\textrm{M-SSA}^{\textrm{GDP}}_t(h)$ to be used as a predictor for $\textrm{GDP}_{t+shift}$ even when $h\neq shift$. Such flexibility enables assessment of the dynamic left-shift of $\textrm{M-SSA}^{\textrm{GDP}}_t(h)$, as illustrated in Figure \ref{{multivar_vs_univar}}, at various forward-shifts of $\textrm{GDP}_{t+shift}$.\\  


When excluding the pandemic, the direct forecasts outperform the mean forecast up to two quarters ahead, see Table \ref{rRMSE_mSSA_direct_mean_without_covid8}.\footnote{However, the pandemic period generally obscures the relationships between predictors and GDP.} However, the M-SSA component predictor, optimized for longer forecast horizons, outperforms the mean benchmark up to 6Q ahead. Additionally, the GDP component predictor optimized for large forecast horizons $h\geq 4$ surpass the direct forecasts for $shift>2$, see Table \ref{rRMSE_mSSA_comp_direct_without_covid7}. Statistical significance of the GDP component predictor, optimized for larger forecast horizons, can be established for at least up to one year ahead.


%???check whether rMSE is decreasing towards sample end (because initial estimate towards 2007 is unreliable)???

<<label=init,results=hide>>=
# Section 5.3

# Select M-SSA components: use M-SSA output tracking BIP
sel_vec_mssa_comp<-select_vec_multi
sel_vec_mssa_comp<-c("BIP")
# Select indicators for direct forecast: all indicators lead to overfitting (worse out-of-sample performances)
# Best design out-of-sample is based on ifo_c and ESI
sel_vec_direct_forecast<-select_vec_multi
sel_vec_direct_forecast<-c("ifo_c","ESI")
# M-SSA looses L observations at start when compared to direct forecast or mean benchmarks: 
#   -therefore the samples are slightly different
# If align_sample==T then the first L observations of mean and direct forecasts are removed to align with M-SSA
#   -Avoid random differences due to unequal samples.
align_sample<-T
# Can define type of regression
reg_type<-"OLS"
reg_type<-"LASSO"
reg_type<-"Ridge"
# Penalty weight in regularization
lambda_reg<-10
# Shift BIP forward by shift_vec + publication lag
shift_vec<-0:5
if (recompute_results)
{
# Select indicators for direct forecast: use all indicators
  sel_indicator_out_sample<-select_vec_multi
# Initialize performance matrices
  MSE_oos_mssa_comp_without_covid_mat<-MSE_oos_mssa_comp_mat<-p_mat_mssa<-p_mat_mssa_components<-p_mat_mssa_components_without_covid<-p_mat_direct<-rRMSE_mSSA_comp_direct<-rRMSE_mSSA_comp_mean<-rRMSE_mSSA_comp_direct_without_covid<-rRMSE_mSSA_comp_mean_without_covid<-rRMSE_mSSA_direct_mean_without_covid<-rRMSE_mSSA_direct_mean<-p_mat_direct_without_covid<-matrix(nrow=length(shift_vec),ncol=length(h_vec))
  final_components_preditor_array<-oos_components_preditor_array<-array(dim=c(length(shift_vec),length(h_vec),nrow(x_mat)))
  dimnames(final_components_preditor_array)<-dimnames(oos_components_preditor_array)<-list(paste("shift=",shift_vec,sep=""), paste("h=",h_vec,sep=""),rownames(x_mat))
  
  dim(p_mat_mssa_components)
# Initialize arrays collecting final predictors, real-time predictors and regression weights
#   -These will be used when analyzing revisions
  track_weights_array<-array(dim=c(length(shift_vec),length(h_vec),nrow(x_mat),length(sel_vec_mssa_comp)+1))
  dimnames(track_weights_array)<-list(paste("shift=",shift_vec,sep=""),
                                      paste("h=",h_vec,sep=""),rownames(x_mat),c("Intercept",sel_vec_mssa_comp))

# Use OLS
# Set-up progress bar: indicates progress in R-console
  pb <- txtProgressBar(min=min(h_vec),max=max(h_vec)-1,style=3)
  
# The following double loop computes all combinations of forward-shifts (of BIP) and forecast horizons (of M-SSA)
  for (shift in shift_vec)#shift<-1
  {
# Progress bar: see R-console
    setTxtProgressBar(pb, shift)
    for (j in h_vec)#j<-1
    {
# Horizon j corresponds to k=j+1-th entry of array    
      k<-j+1
# A. M-SSA component predictor
# Specify data matrix for WLS regression
      if (length(sel_vec_mssa_comp)>1)
      {
        dat<-cbind(c(x_mat[(shift+lag_vec[1]+1):nrow(x_mat),1],rep(NA,shift+lag_vec[1])),t(mssa_array[sel_vec_mssa_comp,,k]))
      } else
      {
        dat<-cbind(c(x_mat[(shift+lag_vec[1]+1):nrow(x_mat),1],rep(NA,shift+lag_vec[1])),(mssa_array[sel_vec_mssa_comp,,k]))
      }
      rownames(dat)<-rownames(x_mat)
      colnames(dat)<-c(colnames(x_mat)[1],sel_vec_mssa_comp)
      nrow(na.exclude(dat))

# Apply the previous function: compute GARCH, WLS regression, out-of-sample MSEs and p-values    
      perf_obj<-optimal_weight_predictor_func(dat,in_out_separator,use_garch,shift,lag_vec,align_sample,reg_type,lambda_reg)
# Retrieve out-of-sample performances 
# a. p-values with/without Pandemic    
      p_mat_mssa_components[shift+1,k]<-perf_obj$p_value
      p_mat_mssa_components_without_covid[shift+1,k]<-perf_obj$p_value_without_covid
# b. MSE forecast error out-of-sample
#   -M-SSA components with/without Pandemic    
      MSE_oos_mssa_comp_mat[shift+1,k]<-MSE_oos_mssa_comp<-perf_obj$MSE_oos
      MSE_oos_mssa_comp_without_covid_mat[shift+1,k]<-MSE_oos_mssa_comp_without_covid<-perf_obj$MSE_oos_without_covid
#   -mean-benchmark with/without Pandemic    
      MSE_mean_oos<-perf_obj$MSE_mean_oos
      MSE_mean_oos_without_covid<-perf_obj$MSE_mean_oos_without_covid
# Here we retrieve the final in-sample predictor (based on the full-sample WLS regression) as well as the 
#    real-time out-of-sample predictor (re-adjusted to new data at each time point)
# We can plot both predictors to illustrate revisions (due to WLS estimation at each time point), see below
      final_in_sample_preditor<-perf_obj$final_in_sample_preditor
      final_components_preditor_array[shift+1,j+1,(nrow(x_mat)-length(final_in_sample_preditor)+1):nrow(x_mat)]<-final_in_sample_preditor
      cal_oos_pred<-perf_obj$cal_oos_pred
      oos_components_preditor_array[shift+1,j+1,(nrow(x_mat)-length(cal_oos_pred)+1):nrow(x_mat)]<-cal_oos_pred
# We can also obtain the regression weights to track changes (systematic vs. noisy revisions) over time
# Note: the variable will be overwritten, i.e., we keep only the last run through the double loop, 
#   corresponding to maximal shift and maximal forecast horizon, see exercise 2.2 below 
      track_weights<-perf_obj$track_weights
      track_weights_array[shift+1,j+1,(nrow(x_mat)-nrow(track_weights)+1):nrow(x_mat),]<-track_weights
      
#----------------      
# B. Direct forecasts
# -The main difference to M-SSA above is the specification of the explanatory variables in the data 
#     matrix dat: we here use x_mat instead of mssa_array. 
#   -We select all indicators (one could easily change this setting but results are only marginally effected as long as ifo and ESi are included)
#   -Note that the data matrix here does not depend on j, in contrast  to the M-SSA components above    
      dat<-cbind(c(x_mat[(shift+lag_vec[1]+1):nrow(x_mat),1],rep(NA,shift+lag_vec[1])),x_mat[,sel_vec_direct_forecast])
      rownames(dat)<-rownames(x_mat)
# Two variants for data set:  
      if (align_sample)
      {
# 1. Same sample as M-SSA (due to filter initialization the first L observations are lost) 
        dat<-dat[L:nrow(dat),]
# Same length as M-SSA      
        nrow(na.exclude(dat))
      } else
      {
# 2. Full data, including the first L observations (makes sense since the data is available) 
        dat<-dat[1:nrow(dat),]
      }
      perf_obj<-optimal_weight_predictor_func(dat,in_out_separator,use_garch,shift,lag_vec,align_sample,reg_type,lambda_reg)
# Retrieve out-of-sample performances: p-values and forecast MSE, with/without Pandemic 
      p_mat_direct[shift+1,k]<-perf_obj$p_value 
      p_mat_direct_without_covid[shift+1,k]<-perf_obj$p_value_without_covid 
      MSE_oos_direct<-perf_obj$MSE_oos
      MSE_oos_direct_without_covid<-perf_obj$MSE_oos_without_covid
      
# Compute rRMSEs
# a. M-SSA Components vs. direct forecast    
      rRMSE_mSSA_comp_direct[shift+1,k]<-sqrt(MSE_oos_mssa_comp/MSE_oos_direct)
# b. M-SSA Components vs. mean benchmark    
      rRMSE_mSSA_comp_mean[shift+1,k]<-sqrt(MSE_oos_mssa_comp/MSE_mean_oos)
# c. Direct forecast vs. mean benchmark    
      rRMSE_mSSA_direct_mean[shift+1,k]<-sqrt(MSE_oos_direct/MSE_mean_oos)
# Same as a, b, c but without Pandemic
      rRMSE_mSSA_comp_direct_without_covid[shift+1,k]<-sqrt(MSE_oos_mssa_comp_without_covid/MSE_oos_direct_without_covid)
      rRMSE_mSSA_comp_mean_without_covid[shift+1,k]<-sqrt(MSE_oos_mssa_comp_without_covid/MSE_mean_oos_without_covid)
      rRMSE_mSSA_direct_mean_without_covid[shift+1,k]<-sqrt(MSE_oos_direct_without_covid/MSE_mean_oos_without_covid)
    }
  }
# Close progress bar
  close(pb)
# Note: possible warnings issued by the GARCH estimation routine during computations can be ignored
  
# Assign column and rownames
  colnames(p_mat_mssa_components)<-colnames(p_mat_direct)<-colnames(p_mat_mssa_components_without_covid)<-
    colnames(rRMSE_mSSA_comp_direct)<-colnames(rRMSE_mSSA_comp_mean)<-
    colnames(rRMSE_mSSA_comp_direct_without_covid)<-colnames(rRMSE_mSSA_comp_mean_without_covid)<-
    colnames(rRMSE_mSSA_direct_mean)<-colnames(rRMSE_mSSA_direct_mean_without_covid)<-
    colnames(p_mat_direct_without_covid)<-colnames(MSE_oos_mssa_comp_mat)<-
    colnames(MSE_oos_mssa_comp_without_covid_mat)<-paste("h=",h_vec,sep="")
  rownames(p_mat_mssa_components)<-rownames(p_mat_direct)<-rownames(p_mat_mssa_components_without_covid)<-
    rownames(rRMSE_mSSA_comp_direct)<-rownames(rRMSE_mSSA_comp_mean)<-
    rownames(rRMSE_mSSA_comp_direct_without_covid)<-rownames(rRMSE_mSSA_comp_mean_without_covid)<-
    rownames(rRMSE_mSSA_direct_mean)<-rownames(rRMSE_mSSA_direct_mean_without_covid)<-
    rownames(p_mat_direct_without_covid)<-rownames(MSE_oos_mssa_comp_mat)<-
    rownames(MSE_oos_mssa_comp_without_covid_mat)<-paste("Shift=",shift_vec,sep="")
# Define list for saving all matrices  
    list_perf<-list(p_mat_mssa_components=p_mat_mssa_components,p_mat_direct=p_mat_direct,
    p_mat_mssa_components_without_covid=p_mat_mssa_components_without_covid,rRMSE_mSSA_comp_direct=rRMSE_mSSA_comp_direct,
    rRMSE_mSSA_comp_mean=rRMSE_mSSA_comp_mean, rRMSE_mSSA_comp_direct_without_covid=rRMSE_mSSA_comp_direct_without_covid,
    rRMSE_mSSA_comp_mean_without_covid=rRMSE_mSSA_comp_mean_without_covid,rRMSE_mSSA_direct_mean=rRMSE_mSSA_direct_mean,
    rRMSE_mSSA_direct_mean_without_covid=rRMSE_mSSA_direct_mean_without_covid,p_mat_direct_without_covid=p_mat_direct_without_covid,
    final_components_preditor_array=final_components_preditor_array,oos_components_preditor_array=oos_components_preditor_array,track_weights_array=track_weights_array,MSE_oos_mssa_comp_mat=MSE_oos_mssa_comp_mat,
    MSE_oos_mssa_comp_without_covid_mat=MSE_oos_mssa_comp_without_covid_mat)
# The results can be saved (overwritten)    
    if (F)
    {
      save(list_perf,file=paste(path.result,"list_perf",sep=""))
    }
} else
{
# Load all results  
  load(file=paste(path.result,"list_perf",sep=""))
  p_mat_mssa_components=list_perf$p_mat_mssa_components
  p_mat_direct=list_perf$p_mat_direct
  p_mat_mssa_components_without_covid=list_perf$p_mat_mssa_components_without_covid
  rRMSE_mSSA_comp_direct=list_perf$rRMSE_mSSA_comp_direct
  rRMSE_mSSA_comp_mean=list_perf$rRMSE_mSSA_comp_mean
  rRMSE_mSSA_comp_direct_without_covid=list_perf$rRMSE_mSSA_comp_direct_without_covid
  rRMSE_mSSA_comp_mean_without_covid=list_perf$rRMSE_mSSA_comp_mean_without_covid
  rRMSE_mSSA_direct_mean=list_perf$rRMSE_mSSA_direct_mean
  rRMSE_mSSA_direct_mean_without_covid=list_perf$rRMSE_mSSA_direct_mean_without_covid
  p_mat_direct_without_covid=list_perf$p_mat_direct_without_covid  
  final_components_preditor_array=list_perf$final_components_preditor_array
  oos_components_preditor_array=list_perf$oos_components_preditor_array
  track_weights_array=list_perf$track_weights_array
  MSE_oos_mssa_comp_mat=list_perf$MSE_oos_mssa_comp_mat
  MSE_oos_mssa_comp_without_covid_mat=list_perf$MSE_oos_mssa_comp_without_covid_mat
}

# HAC-adjusted p-values of out-of-sample (M-SSA) components predictor when targeting forward-shifted BIP
#   -Evaluation based on out-of-sample span starting at in_out_separator and ending on Jan-2025
#   -Without singular Pandemic
p_mat_mssa_components_without_covid
# The link between the new predictor and future BIP is statistically significant up to multiple quarters ahead 
#   -Designs optimized for larger forecast horizons (columns with h>=4) seem to perform significantly up to 
#     one year ahead

# Same but for direct forecast
p_mat_direct_without_covid[,1]



# -Out of sample rRMSEs
# -Without pandemic
# a. M-SSA against mean: numbers smaller one signify outperformance of M-SSA
rRMSE_mSSA_comp_mean_without_covid
# b. M-SSA against direct forecast
rRMSE_mSSA_comp_direct_without_covid
# c. Direct forecast against mean
rRMSE_mSSA_direct_mean_without_covid[,1]


@
<<label=ats_mba_2,echo=FALSE,results=tex>>=


# P-values
mat1<-round(p_mat_mssa_components_without_covid,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("HAC adjusted p-values of regressions of M-SSA component predictors optimized for forecast horizons $h=0,...,6$  (the columns) on BIP shifted forward by shift=0,...,5 (the rows). Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("p_val_wc",sep=""),
center = "centering", file = "", floating = FALSE)

# rRMSEs: M-SSA vs. mean
mat1<-round(rRMSE_mSSA_comp_mean_without_covid,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs of M-SSA components predictor benchmarked against the expanding mean of BIP. Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("rRMSE_mSSA_comp_mean_wc",sep=""),
center = "centering", file = "", floating = FALSE)

@


\section{Revisions}\label{revisions}



<<label=init,results=hide>>=
# Section 6.1: revisions (regression)

# Select h and shift
h<-4
shift<-4

# Plot final predictor (based on full-sample regression of M-SSA on future BIP)
file = "./Figures/revisions1.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)

par(mfrow=c(1,1))
mplot<-cbind(final_components_preditor_array[shift,h,],oos_components_preditor_array[shift,h,])
mplot<-mplot[L:nrow(mplot),]
colnames(mplot)<-c("Final predictor","Real-time out-of-sample predictor")
colo<-c("blue",rainbow(length(select_vec_multi)))
main_title<-paste("Final vs. real-time predictor: h=",h,", shift=",shift,sep=""
)
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
#  mtext(colnames(mplot)[i],col=colo[i],line=-i)
}
abline(h=0)
#abline(v=which(rownames(mplot)<=date_to_fit)[length(which(rownames(mplot)<=date_to_fit))],lwd=2,lty=2)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")

box()

dev.off()

# Plot the regression weights 
file = "./Figures/revisions2.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 6, height = 6)


par(mfrow=c(1,1))
mplot<-track_weights_array[shift,h,,]
mplot<-mplot[(L:nrow(mplot)),]
colnames(mplot)[2]<-"GDP"
#mplot<-t(t(mplot)/mplot[nrow(mplot),])
#colnames(mplot)[2:ncol(track_weights)]<-paste("Weight of M-SSA component ",colnames(track_weights)[2:ncol(track_weights)])
colo<-c("black","blue","red")
main_title<-paste("Intercept and regression weight over time: h=",h,", shift=",shift,sep="")
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],lwd=1,ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
#  mtext(colnames(mplot)[i],col=colo[i],line=-i)
}
abline(h=0)
#abline(v=which(rownames(mplot)<=date_to_fit)[length(which(rownames(mplot)<=date_to_fit))],lwd=2,lty=2)
axis(1,at=c(1,4*1:(nrow(mplot)/4)),labels=rownames(mplot)[c(1,4*1:(nrow(mplot)/4))])
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()

dev.off()
@
Revisions refer to changes in the historical values of a time series resulting from updates with new information. Revisions of the M-SSA component predictor can arise from data updates, which we do not analyze further here\footnote{Except for BIP, the other indicators are not or only slightly revised. Moreover, the smoothing effect of filters mitigates the effect of revisions when compared to direct forecasts.}, or from updates to predictor parameters. The latter can be further separated into changes in VAR parameters and regression weights. 


\subsection{Revisions: Regression Equation Only}

For illustration, we here focus on a forecast horizon $h=\Sexpr{h}$ for the BIP component predictor and a forward-shift $shift=\Sexpr{shift}$ for BIP, noting that similar results would be obtained with other combinations of $h$ and $shift$. 
%???Check left-shift of MA-inversion of M-SSA and M-MSE
%??? Check forecast excess for HP-C
%??? Justification HP(160): replace HP(1600) by AR(2) with similar persistency but shorter cycle lengthi, i.e. $a_1=-2"persistency*acos(\theta, a_2=persistency$.
Fig.\eqref{revisions1} compares the final and real-time predictors: as the sample size increases, the real-time predictor converges steadily to the final predictor and the rate of convergence is partially determined by the simplicity of our design, which avoids incorporating additional M-SSA components. 
As a confirmation, Fig.\eqref{revisions2} displays the evolution of the intercept and regression weights over time: with increasing sample size, these estimates seem to converge to fixed points, indicating both the stationarity of the process and the consistency of the estimates (note, however, the slightly elevated values of the regression weight assigned to the M-SSA component during the financial crisis and the pandemic, suggesting a stronger link between the target and the predictor).  In contrast, more complex designs based on multiple M-SSA components can exhibit substantial fluctuations in the regression parameters, sometimes changing signs. This suggests instability and complicates interpretation.
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/revisions1.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Revisions of the M-SSA GDP component predictor are shown, with the final predictor in blue and the real-time design in red. These revisions result from quarterly updates to the regression equations. The M-SSA filter itself remains fixed, based on data up to January 2008.", sep = "")
cat("\\label{revisions1}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/revisions2.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=4.5in]{", file, "}\n",sep = "")
cat("\\caption{Revisions of intercept and regression weight.", sep = "")
cat("\\label{revisions2}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@


\subsection{Revisions: M-SSA Only}

The second source of revisions in the M-SSA component predictor arises from updates to the VAR model within the M-SSA filter. We compare the original estimates, based on data up to January 2008, with the final estimates obtained using $h=\Sexpr{h}$ and $shift=\Sexpr{shift}$ (similar findings apply to other values of forecast horizon and forward-shift).  For consistency, we excluded the entire pandemic episode from the data. Fig.\eqref{up_dated_ma_inv_multi_ip} compares the MA-inversions (impulse responses) of the BIP equation derived from the 'old' and the updated VAR models: unlike the former, the latter incorporates ESI as an additional explanatory variable for BIP. Fig.\eqref{bk_2008_all} illustrates the resulting effect on the M-SSA filter targeting HP-BIP at forecast horizon $h=\Sexpr{h}$. The updated filter (right panel) assigns more weight to the additional 'leading' indicators relative to BIP. Finally, Fig.\eqref{revisions3} compares the M-SSA BIP predictors. To isolate the effect of the regression revision, the figure displays standardized series. The update to the VAR model influences the left-shift of the predictor (blue line), which appears slightly 'faster' than the original predictor (red line). This suggests that the out-of-sample performance of the M-SSA component predictor may be better than reported in Section \eqref{oosp}, which is based on the fixed and increasingly outdated version of M-SSA.
<<label=init,results=hide>>=
# Section 6.2: revisions due to VAR-updating

# Up-date M-SSA and M-MSE
# In-sample span for VAR, use all data for VAR
date_to_fit_all<-"3000"
# Remove Pandemic
x_mat_wc<-x_mat[c(which(rownames(x_mat)<2020),which(rownames(x_mat)>2021)),]
par(mfrow=c(1,1))
ts.plot(x_mat_wc)

# We can select type of VAR model
VAR_type="BVAR"
VAR_type="VAR"
if (VAR_type=="BVAR")
{
# Simon's settings for BVAR(4)  
  lambda_BVAR <- 10 
  p_full<-4
  q_full<-0
}
if (VAR_type=="VAR")
{
# Marc's settings for VAR  
  p_full<-p
  q_full<-q
}

# Run the M-SSA wrapper, see tutorial 7.2
#   -The function computes M-SSA and M-MSE for each forecast horizon h in h_vec
if (recompute_results)
{
  final_mssa_indicator_obj<-compute_mssa_BIP_predictors_func(x_mat_wc,lambda_HP,L,date_to_fit_all,p_full,q_full,ht_mssa_vec,h_vec,f_excess,lag_vec,select_vec_multi,VAR_type,lambda_BVAR)
  save(final_mssa_indicator_obj,file=paste(path.result,"/final_mssa_indicator_obj",sep=""))
} else
{
  load(file=paste(path.result,"/final_mssa_indicator_obj",sep=""))
}
# Final M-SSA components
final_mssa_array<-final_mssa_indicator_obj$mssa_array


#----------------------
# Compute up-dated M-SSA component predictors 

if (length(sel_vec_mssa_comp)>1)
{
  dat<-cbind(c(x_mat_wc[(shift+lag_vec[1]+1):nrow(x_mat_wc),1],rep(NA,shift+lag_vec[1])),t(final_mssa_array[sel_vec_mssa_comp,,h+1]))
} else
{
  dat<-cbind(c(x_mat_wc[(shift+lag_vec[1]+1):nrow(x_mat_wc),1],rep(NA,shift+lag_vec[1])),(final_mssa_array[sel_vec_mssa_comp,,h+1]))
}
lm_obj<-lm(dat[,1]~dat[,2:ncol(dat)])

optimal_weights<-lm_obj$coef
# Compute predictor for each forward-shift  
if (length(sel_vec_mssa_comp)>1)
{
  final_mssa_predictor<-optimal_weights[1]+dat[,2:ncol(dat)]%*%optimal_weights[2:length(optimal_weights)]
} else
{
  final_mssa_predictor<-optimal_weights[1]+dat[,2:ncol(dat)]*optimal_weights[2:length(optimal_weights)]
}

# Compare and plot old and final M-SSA BIP component predictors
#   Standardize predictors to isolate VAR-revision from total revision (including regression revission)
mssa_final_vs_prem_wc<-cbind(final_mssa_predictor,final_components_preditor_array[shift,h,c(which(rownames(x_mat)<2020),which(rownames(x_mat)>2021))])
rownames(mssa_final_vs_prem_wc)<-rownames(x_mat_wc)
colnames(mssa_final_vs_prem_wc)<-c("Predictor based on final M-SSA","Predictor based on 2008-M-SSA")


file = "./Figures/revisions3.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7, height = 7)
par(mfrow=c(1,1))

colo<-c("blue","red")
mplot<-scale(mssa_final_vs_prem_wc)
mplot<-mplot[L:nrow(mplot),]
colnames(mplot)<-colnames(mssa_final_vs_prem_wc)
main_title<-paste("GDP component predictors: final and 2008-MSSA (h=",h,", shift=",shift,")",sep="")
plot(mplot[,1],main=main_title,axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))
#mtext(colnames(mplot)[1],col=colo[1],line=-1)
for (jj in 1:ncol(mplot))
{
  lines(mplot[,jj],col=colo[jj],lwd=1,lty=1)
#  mtext(colnames(mplot)[jj],col=colo[jj],line=-jj)
}
abline(h=0)
axis(1,at=c(1,12*1:(nrow(mplot)/12)),labels=rownames(mplot)[c(1,12*1:(nrow(mplot)/12))])
axis(2)
legend("bottomleft", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()
dev.off()



#---------------------------------------------
# Compute impulse responses of old and of up-dated VAR
if (recompute_results)
{
# VAR based on full data set without pandemic  
  data_fit<-x_mat_wc

  set.seed(12)
  V_obj_full<-VARMA(data_fit,p=p,q=q)
  threshold<-1.5
  V_obj_full<-refVARMA(V_obj_full, thres = threshold)
  save(V_obj_full,file=paste(path.result,"/VAR_full",sep=""))
  
# VAR based on data pre 2008  
  data_fit<-x_mat_wc[which(rownames(x_mat_wc)<date_to_fit),]

  set.seed(12)
  V_obj_2008<-VARMA(data_fit,p=p,q=q)
  threshold<-1.5
  V_obj_2008<-refVARMA(V_obj_2008, thres = threshold)
  save(V_obj_2008,file=paste(path.result,"/VAR_2008",sep=""))

} else
{
    load(file=paste(path.result,"/VAR_full",sep=""))
    load(file=paste(path.result,"/VAR_2008",sep=""))

}

# Diagnostics are OK
if (F)
{
  MTSdiag(V_obj_full)
  MTSdiag(V_obj_2008)
}

# Compute MA-inversion
compute_xi_func<-function(V_obj,L)
{
  Sigma<-V_obj$Sigma
  V_obj$Phi
  V_obj$Theta
  n<-dim(Sigma)[1]
  # MA inversion
  xi_psi<-PSIwgt(Phi = V_obj$Phi, Theta = V_obj$Theta, lag = L, plot = F, output = F)
  xi_p<-xi_psi$psi.weight
  # Transform Xi_p into Xi: first L entries, from left to right, are weights of first WN, next L entries are weights of second WN 
  xi<-matrix(nrow=n,ncol=n*L)
  for (i in 1:n)
  {
    for (j in 1:L)
      xi[,(i-1)*L+j]<-xi_p[,i+(j-1)*n]
  }
  return(list(xi=xi))
}

xi_full<-compute_xi_func(V_obj_full,L)$xi
xi_2008<-compute_xi_func(V_obj_2008,L)$xi


# Plot MA inversions
file = "./Figures/up_dated_ma_inv_multi_ip.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7, height = 7)
colo<-c("black", "red", "green", "blue", "orange", "dimgray")
# Select BIP component
ih<-1
par(mfrow=c(1,2))
# 2008
xi<-compute_xi_func(V_obj_2008,L)$xi
mplot<-xi[ih,1:min(10,L)]
for (j in 2:n)
{
  mplot<-cbind(mplot,xi[ih,(j-1)*L+1:min(10,L)])
}
colnames(mplot)<-select_vec_multi
colnames(mplot)[1]<-"GDP"
plot(mplot[,1],main=paste("MA inversion GDP: 2008",sep=""),axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=1:nrow(mplot)-1)
axis(2)
legend("topright", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
box()



# full data set
xi<-compute_xi_func(V_obj_full,L)$xi

mplot<-xi[ih,1:min(10,L)]
for (j in 2:n)
{
  mplot<-cbind(mplot,xi[ih,(j-1)*L+1:min(10,L)])
}

plot(mplot[,1],main=paste("Full data set",sep=""),axes=F,type="l",xlab="",ylab="",col=colo[1],ylim=c(min(na.exclude(mplot)),max(na.exclude(mplot))))

for (i in 1:ncol(mplot))
{
  lines(mplot[,i],col=colo[i],lwd=1,lty=1)
}
abline(h=0)
axis(1,at=1:nrow(mplot),labels=1:nrow(mplot)-1)
axis(2)
box()

dev.off()



#---------------------------------------------
# Plot M-SSA filter weights of old and of up-dated VAR


bk_all<-matrix(final_mssa_indicator_obj$bk_x_array[select,select,,"h=4"],nrow=L)
bk_2008<-matrix(mssa_indicator_obj$bk_x_array[select,select,,"h=4"],nrow=L)
colnames(bk_2008)<-colnames(bk_all)<-select_vec_multi

file = "./Figures/bk_2008_all.pdf"
pdf(file = paste(path.out,file,sep=""), paper = "special", width = 7, height = 7)
colo<-c("black", "red", "green", "blue", "orange", "dimgray")

par(mfrow=c(1,2))
mplot<-bk_2008
colnames(mplot)[1]<-"GDP"
ts.plot(mplot,col=colo,main=paste("M-SSA data up to 2008: h=",h,sep=""),xlab="")
#for (i in 1:ncol(mplot))
#  mtext(colnames(mplot)[i],col=colo[i],line=-i)
legend("topright", legend = colnames(mplot), col = colo, lty = 1, lwd = 1, bty = "n")
mplot<-bk_all
ts.plot(mplot,col=colo,main="Full data set",xlab="")
#for (i in 1:ncol(mplot))
#  mtext(colnames(mplot)[i],col=colo[i],line=-i)

dev.off()







@
<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/up_dated_ma_inv_multi_ip.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=5in]{", file, "}\n",sep = "")
cat("\\caption{MA-inversion (impulse response) of VAR: data up to Jan-2008 (left) vs. entire data set  without pandemic (right).", sep = "")
cat("\\label{up_dated_ma_inv_multi_ip}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@

<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/bk_2008_all.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=5in]{", file, "}\n",sep = "")
cat("\\caption{M-SSA filter tracking HP-GDP at forecast horizon $h=4$: data up to Jan-2008 (left) vs. entire data set without pandemic (right).", sep = "")
cat("\\label{bk_2008_all}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@


<<label=z_box_plot_pure_mba_2.pdf,echo=FALSE,results=tex>>=
file = "./Figures/revisions3.pdf"
cat("\\begin{figure}[H]")
cat("\\begin{center}")
cat("\\includegraphics[height=3in, width=5in]{", file, "}\n",sep = "")
cat("\\caption{Revisions resulting from updates to the VAR model in M-SSA optimized for $h=shift=4$. To isolate the effect of the regression revision, all series are standardized. The up-dated M-SSA (blue) is left-shifted at the zero-crossings and appears slightly faster. For consistency, the entire pandemic episode has been removed.", sep = "")
cat("\\label{revisions3}}", sep = "")
cat("\\end{center}")
cat("\\end{figure}")
@



\section{Summary and Conclusion}


Classic direct forecasts of BIP can outperform simple benchmarks, such as the mean, up to two quarters ahead. However, this limited forecast horizon is often insufficient for certain applications. A key challenge with direct forecasts is that the relevant indicators tend to be noisy, which can mask the true signal and lead to overfitting. In particular, the predictor struggles to timely track dips (slowdowns, recessions) or peaks (recoveries, expansions). To address this issue, we apply a HP(160)-filter to smooth the data, with the smoothing parameter $\lambda=160$ reflecting a more adaptive design than the classic quarterly HP, in line with an intended forecast horizon of up to one year ahead. The resulting predictor tends to outperform the classic direct forecasts in terms of statistical significance, mainly due to a slight left-shift noticeable at sharp recession dips. However, despite the filtering, the predictor remains somewhat noisy, potentially producing excessive noisy zero-crossings at the transitions between recessions and expansions. This issue is partly due to noise leakage inherent in the one-sided HP filter. \\

To address these problems, we propose a multivariate extension of SSA based on Wildi (2024). Unlike the univariate HP filter, the M-SSA can leverage cross-sectional information from indicators leading BIP in real time while controlling for the rate of zero-crossings of the predictor. Consequently, the multivariate filter outputs become increasingly left-shifted as the forecast horizon lengthens, allowing dips and peaks of the target series to be tracked more systematically, while reducing the occurrence of noisy zero-crossings. However, since M-SSA does not explicitly target BIP, an additional step is necessary to derive the final BIP predictor. We propose two approaches: a simple equally-weighted aggregate, assuming all M-SSA components are equally important for predicting BIP, and an optimally weighted predictor based on a regression of the M-SSA components on future BIP.\\

For illustration, we consider a simple approach based on regressing the single M-SSA BIP output on future BIP, thereby ignoring the other filter outputs. This predictor is intuitively appealing because the future HP-BIP—i.e., the target of M-SSA—is the low-frequency component of the future BIP target. Consequently, a strong link between M-SSA and future HP-BIP also indicates a connection with BIP, even if the statistical significance is obscured by the noise inherent in BIP. Out-of-sample performance suggests that this predictor is statistically significant at horizons up to one year. Moreover, designs optimized for larger forecast horizons outperform the mean benchmark at all considered forecast horizons, and the predictor exceeds the performance of direct forecasts—based on unfiltered or HP filtered indicators—at horizons longer than two quarters. An analysis of revision errors arising from quarterly updates of the proposed M-SSA BIP component predictor indicates that the regression parameters, the VAR model, and the resulting M-SSA filters stabilize after an initial burn-in period. This stability enhances the explainability and interpretability of the predictor.\\

In conclusion, the new predictor design integrates the traditional direct forecast approach with a novel multivariate filter to target BIP up to one year ahead. This multivariate approach leverages a set of economic indicators leading BIP in real time while controlling the smoothness of the predictor through the zero-crossing rate. 

\newpage

\section{Appendix}

\subsection{Performances: Without Pandemic}


<<label=ats_mba_2,echo=FALSE,results=tex>>=


mat1<-round(p_mat_mssa_components_without_covid,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("HAC adjusted p-values of regressions of M-SSA component predictors optimized for forecast horizons $h=0,...,6$  (the columns) on BIP shifted forward by shift=0,...,5 (the rows). Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("p_val_wc5",sep=""),
center = "centering", file = "", floating = FALSE)


mat1<-round(rRMSE_mSSA_comp_mean_without_covid,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs of M-SSA components predictor benchmarked against the expanding mean of BIP. Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("rRMSE_mSSA_comp_mean6",sep=""),
center = "centering", file = "", floating = FALSE)



mat1<-round(rRMSE_mSSA_comp_direct_without_covid,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs of M-SSA components predictor benchmarked against the direct forecasts. Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("rRMSE_mSSA_comp_direct_without_covid7",sep=""),
center = "centering", file = "", floating = FALSE)

mat1<-matrix(round(rRMSE_mSSA_direct_mean_without_covid[,1],3),nrow=1)
colnames(mat1)<-rownames(rRMSE_mSSA_direct_mean_without_covid)
rownames(mat1)<-"RRMSE"
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs direct forecasts benchmarked against the expanding mean. Out-of-sample span starting in Jan-2007, without pandemic."),
label=paste("rRMSE_mSSA_direct_mean_without_covid8",sep=""),
center = "centering", file = "", floating = FALSE)




@


\newpage
\subsection{Performances: Including Singular Pandemic Data}

<<label=ats_mba_2,echo=FALSE,results=tex>>=


mat1<-round(p_mat_mssa_components,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("HAC adjusted p-values of regressions of M-SSA component predictors optimized for forecast horizons $h=0,...,6$  (the columns) on BIP shifted forward by shift=0,...,5 (the rows). Out-of-sample span starting in Jan-2007, including the pandemic."),
label=paste("p_val1",sep=""),
center = "centering", file = "", floating = FALSE)


mat1<-round(rRMSE_mSSA_comp_mean,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs of M-SSA components predictor benchmarked against the expanding mean of BIP. Out-of-sample span starting in Jan-2007, including the pandemic."),
label=paste("rRMSE_mSSA_comp_mean2",sep=""),
center = "centering", file = "", floating = FALSE)


mat1<-round(rRMSE_mSSA_comp_direct,3)
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs of M-SSA components predictor benchmarked against the direct forecasts. Out-of-sample span starting in Jan-2007, including the pandemic."),
label=paste("rRMSE_mSSA_comp_direct3",sep=""),
center = "centering", file = "", floating = FALSE)


mat1<-matrix(round(rRMSE_mSSA_direct_mean[,1],3),nrow=1)
colnames(mat1)<-rownames(rRMSE_mSSA_direct_mean)
rownames(mat1)<-"RRMSE"
#latex(cor_vec, dec = 1, , caption = "Example of using latex to create table",
#center = "centering", file = "", floating = FALSE)
xtable(mat1, dec = 1,digits=rep(3,dim(mat1)[2]+1),
paste("rRMSEs direct forecasts benchmarked against the expanding mean. Out-of-sample span starting in Jan-2007, including the pandemic."),
label=paste("rRMSE_mSSA_direct_mean4",sep=""),
center = "centering", file = "", floating = FALSE)



@






\end{document}
